{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exports raw data from mimic-iv database\n",
    "\n",
    "Only the following care unit patients are exported:\n",
    "- Coronary Care unit (CCU)\n",
    "- Cardiac Vascular Intensive Care unit (CVICU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.utils import *\n",
    "from projects.common import *\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool, RLock\n",
    "from configobj import ConfigObj\n",
    "import numpy as np\n",
    "import getpass\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n"
     ]
    }
   ],
   "source": [
    "def connect_db():\n",
    "    db_dir = os.path.abspath('') + \"/../../../db\"\n",
    "    return connect_to_database(db_dir)\n",
    "\n",
    "\n",
    "connect_db()\n",
    "\n",
    "# def merge_lab_df(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "#     target_cols = ['subject_id', 'hadm_id', 'charttime', 'specimen_id']\n",
    "#     df1 = df1.sort_values(target_cols)\n",
    "#     df2 = df2.sort_values(target_cols)\n",
    "#     df2 = df2.loc[:, ~df2.columns.isin(target_cols)]\n",
    "#     return pd.concat([df1, df2], axis=1)\n",
    "\n",
    "\n",
    "def get_db_table_as_df_ext(_schema_type: str, _table: str,\n",
    "                           _chunk: int = 10000):\n",
    "    \"\"\"Wrapper for generating dataframe from the db. \"\"\"\n",
    "    (query_schema_core,\n",
    "     query_schema_hosp,\n",
    "     query_schema_icu,\n",
    "     query_schema_derived,\n",
    "     conn) = connect_db()\n",
    "\n",
    "    if _schema_type == 'core':\n",
    "        _query_schema = query_schema_core\n",
    "    if _schema_type == 'hosp':\n",
    "        _query_schema = query_schema_hosp\n",
    "    if _schema_type == 'icu':\n",
    "        _query_schema = query_schema_icu\n",
    "    if _schema_type == 'derived':\n",
    "        _query_schema = query_schema_derived\n",
    "    else:\n",
    "        _query_schema = None\n",
    "\n",
    "    df_iter, num_entries = get_database_table_as_dataframe(\n",
    "        conn, _query_schema, _table, _chunk_size=_chunk*MP_NUM_PROCESSES)\n",
    "    num_entries = math.ceil(num_entries / (_chunk*MP_NUM_PROCESSES))\n",
    "    return df_iter, num_entries\n",
    "\n",
    "\n",
    "def get_info_save_path(data_dir: str, stay_id: int):\n",
    "    return os.path.join(data_dir, 'info_'+str(stay_id)+'.dsv')\n",
    "\n",
    "\n",
    "def get_data_save_path(data_dir: str, stay_id: int):\n",
    "    return os.path.join(data_dir, 'data_'+str(stay_id)+'.dsv')\n",
    "\n",
    "\n",
    "def save_data_dsv_ext(save_path: str, data: dict) -> None:\n",
    "    save_dsv(save_path, pd.DataFrame(data))\n",
    "\n",
    "\n",
    "def create_dummy_files_func(export_dir, _custom_icustays_list, pid):\n",
    "    for icustay_id in tqdm(_custom_icustays_list):\n",
    "        # if icustay_id != 39060235:\n",
    "        #     continue\n",
    "        save_path = get_data_save_path(export_dir, icustay_id)\n",
    "        assert not os.path.exists(save_path)\n",
    "        save_data_dsv_ext(save_path, pd.DataFrame(DataTable().data))\n",
    "\n",
    "\n",
    "def create_dummy_files(export_dir: str, _custom_icustays_list: list):\n",
    "    \"\"\" Create empty dummy .dsv files.\"\"\"\n",
    "    parallel_processing(create_dummy_files_func, MP_NUM_PROCESSES,\n",
    "                        export_dir, _custom_icustays_list)\n",
    "    print(\"Created dummy .dsv files.\")\n",
    "\n",
    "\n",
    "def split_df(df: pd.DataFrame, num_processes: int = 8):\n",
    "    interval = math.ceil(len(df)/num_processes)\n",
    "    dfs = [df.iloc[interval*i:interval*(i+1)]\n",
    "           for i in range((num_processes-1))]\n",
    "    dfs += [df.iloc[interval*(num_processes-1):]]\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def parallel_processing_ext(_func,\n",
    "                            _df_iter,\n",
    "                            _num_entries: int,\n",
    "                            _custom_icustays_list: list):\n",
    "    \"\"\"Wrapper for parallel processing. Sorts the dataframe based on\n",
    "    `sort_list` before running the `func`.\n",
    "\n",
    "    TODO: df should be splitted up based on `stay_id`, i.e. where all\n",
    "    the `stay_id` are assigned to the same process. If not may cause reading\n",
    "    error because this id determines which dsv file to read from. The current\n",
    "    hack is to create a large enough df chunk so that this error situation\n",
    "    will not occur.\n",
    "    \"\"\"\n",
    "    sort_list = ['subject_id', 'hadm_id', 'stay_id',\n",
    "                 'charttime', 'starttime', 'endtime', ]\n",
    "    # mem_flag, df_mem = False, pd.DataFrame()\n",
    "    for df in tqdm(_df_iter, total=_num_entries):\n",
    "\n",
    "        if 'stay_id' in df.columns.tolist():\n",
    "            df = df[df.stay_id.isin(_custom_icustays_list)]\n",
    "            # df_mem = pd.concat([df_mem, df]) if mem_flag else df\n",
    "            # uc = df_mem.nunique(axis=1)\n",
    "            # if uc < MP_NUM_PROCESSES:\n",
    "            #     mem_flag = True\n",
    "            #     continue\n",
    "            # else:\n",
    "            #     df = df_mem\n",
    "            #     mem_flag, df_mem = False, pd.DataFrame()\n",
    "\n",
    "        df = df.sort_values(\n",
    "            by=[i for i in sort_list if i in df.columns.tolist()])\n",
    "        dfs = split_df(df, MP_NUM_PROCESSES)\n",
    "        parallel_processing(_func, MP_NUM_PROCESSES, dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_func_factory(append_func, export_dir: str):\n",
    "\n",
    "    global export_func\n",
    "\n",
    "    def export_func(dfs, pid):\n",
    "\n",
    "        stay_id_mem = -1\n",
    "        subject_id_mem = -1\n",
    "        hadm_id_mem = -1\n",
    "\n",
    "        stay_ids_dt = {}  # dict of DataTable\n",
    "        stay_ids_path = {}  # dict of paths\n",
    "\n",
    "        save_path = None\n",
    "        save_flag = -1\n",
    "\n",
    "        df = dfs[0]\n",
    "        it = InfoTable()\n",
    "        dt = DataTable()\n",
    "        for df_i in df.iterrows():\n",
    "            df_row = df_i[1]\n",
    "\n",
    "            if 'stay_id' in df.columns.tolist():\n",
    "                save_flag = 0\n",
    "                stay_id = df_row['stay_id']\n",
    "\n",
    "                if stay_id_mem == -1:\n",
    "                    # Initial loading of data\n",
    "                    stay_id_mem = df_row['stay_id']\n",
    "                    save_path = get_data_save_path(export_dir, stay_id)\n",
    "                    dt.data = load_data_dsv(save_path)\n",
    "\n",
    "                elif df_row['stay_id'] != stay_id_mem:\n",
    "                    # Only load data when the id changes.\n",
    "                    # Saves the previous data first before loading.\n",
    "                    save_path = get_data_save_path(export_dir, stay_id_mem)\n",
    "                    save_data_dsv_ext(save_path, dt.data)\n",
    "                    stay_id_mem = df_row['stay_id']\n",
    "                    save_path = get_data_save_path(export_dir, stay_id)\n",
    "                    dt.data = load_data_dsv(save_path)\n",
    "\n",
    "                dt = append_func(dt, df_row, df.columns.tolist())\n",
    "\n",
    "            else:\n",
    "                # elif 'hadm_id' not in df.columns.tolist():\n",
    "                save_flag = 1\n",
    "                sub_id = str(df_row['subject_id'])\n",
    "\n",
    "                if sub_id not in custom_icustays_dict:\n",
    "                    continue\n",
    "\n",
    "                if subject_id_mem == -1:\n",
    "                    # Initial loading of data\n",
    "                    subject_id_mem = sub_id\n",
    "                    for _, stay_ids in custom_icustays_dict[sub_id].items():\n",
    "                        for stay_id in stay_ids:\n",
    "                            save_path = get_data_save_path(export_dir, stay_id)\n",
    "                            _dt = DataTable()\n",
    "                            _dt.data = load_data_dsv(save_path)\n",
    "                            stay_ids_dt[stay_id] = _dt\n",
    "                            stay_ids_path[stay_id] = save_path\n",
    "\n",
    "                elif subject_id_mem != sub_id:\n",
    "                    # Only load data when the id changes.\n",
    "                    # Saves the previous data first before loading.\n",
    "                    subject_id_mem = sub_id\n",
    "                    for stay_id, stay_id_dt in stay_ids_dt.items():\n",
    "                        save_data_dsv_ext(\n",
    "                            stay_ids_path[stay_id], stay_id_dt.data)\n",
    "                    stay_ids_dt, stay_ids_path = {}, {}\n",
    "                    for _, stay_ids in custom_icustays_dict[sub_id].items():\n",
    "                        for stay_id in stay_ids:\n",
    "                            save_path = get_data_save_path(export_dir, stay_id)\n",
    "                            _dt = DataTable()\n",
    "                            _dt.data = load_data_dsv(save_path)\n",
    "                            stay_ids_dt[stay_id] = _dt\n",
    "                            stay_ids_path[stay_id] = save_path\n",
    "\n",
    "                for _, stay_ids in custom_icustays_dict[sub_id].items():\n",
    "                    for stay_id in stay_ids:\n",
    "                        info_save_path = get_info_save_path(\n",
    "                            STRUCTURED_EXPORT_DIR, stay_id)\n",
    "                        it.data = load_info_dsv(info_save_path)\n",
    "                        icu_intime = it.data['value'][13]\n",
    "                        icu_outtime = it.data['value'][14]\n",
    "                        if pd.Timestamp(str(icu_intime)) <= df_row['charttime'] <= pd.Timestamp(str(icu_outtime)):\n",
    "                            stay_ids_dt[stay_id] = append_func(\n",
    "                                stay_ids_dt[stay_id], df_row, df.columns.tolist())\n",
    "\n",
    "            # else:\n",
    "            #     save_flag = 2\n",
    "            #     sub_id = str(df_row['subject_id'])\n",
    "            #     hadm_id = str(df_row['hadm_id'])\n",
    "\n",
    "            #     if sub_id not in custom_icustays_dict:\n",
    "            #         continue\n",
    "            #     if hadm_id not in custom_icustays_dict[sub_id]:\n",
    "            #         continue\n",
    "\n",
    "            #     stay_ids = custom_icustays_dict[sub_id][hadm_id]\n",
    "\n",
    "            #     if subject_id_mem == -1 and hadm_id_mem == -1:\n",
    "            #         # Initial loading of data\n",
    "            #         subject_id_mem = sub_id\n",
    "            #         hadm_id_mem = hadm_id\n",
    "            #         for stay_id in stay_ids:\n",
    "            #             save_path = get_data_save_path(export_dir, stay_id)\n",
    "            #             _dt = DataTable()\n",
    "            #             _dt.data = load_data_dsv(save_path)\n",
    "            #             stay_ids_dt.append(_dt)\n",
    "            #             stay_ids_path.append(save_path)\n",
    "\n",
    "            #     elif subject_id_mem != sub_id or hadm_id_mem != hadm_id:\n",
    "            #         # Only load data when the id changes.\n",
    "            #         # Saves the previous data first before loading.\n",
    "            #         subject_id_mem = sub_id\n",
    "            #         hadm_id_mem = hadm_id\n",
    "            #         for stay_id_dt, stay_id_path in zip(stay_ids_dt,\n",
    "            #                                             stay_ids_path):\n",
    "            #             save_data_dsv_ext(stay_id_path, stay_id_dt.data)\n",
    "            #         stay_ids_dt, stay_ids_path = [], []\n",
    "            #         for stay_id in stay_ids:\n",
    "            #             save_path = get_data_save_path(export_dir, stay_id)\n",
    "            #             _dt = DataTable()\n",
    "            #             _dt.data = load_data_dsv(save_path)\n",
    "            #             stay_ids_dt.append(_dt)\n",
    "            #             stay_ids_path.append(save_path)\n",
    "\n",
    "            #     for idx, stay_id_dt in enumerate(stay_ids_dt):\n",
    "            #         info_save_path = get_info_save_path(\n",
    "            #             STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            #         it.data = load_info_dsv(info_save_path)\n",
    "            #         icu_intime = it.data['value'][13]\n",
    "            #         icu_outtime = it.data['value'][14]\n",
    "            #         if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "            #             stay_ids_dt[idx] = append_func(\n",
    "            #                 stay_id_dt, df_row, df.columns.tolist())\n",
    "\n",
    "        if save_flag == 0:\n",
    "            # Saves the final data.\n",
    "            save_data_dsv_ext(save_path, dt.data)\n",
    "\n",
    "        elif save_flag == 1 or save_flag == 2:\n",
    "            # Saves the final data.\n",
    "            for stay_id, stay_id_dt in stay_ids_dt.items():\n",
    "                save_data_dsv_ext(stay_ids_path[stay_id], stay_id_dt.data)\n",
    "            stay_ids_dt, stay_ids_path = {}, {}\n",
    "\n",
    "    return export_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save labevents_info table from db.\n",
    "# (_, _, _, query_schema_derived, conn) = connect_db()\n",
    "# df = get_database_table_as_dataframe(\n",
    "#     conn, query_schema_derived, 'labevents_info')\n",
    "# df = df.sort_values('itemid')\n",
    "# df.to_csv(\"../../../\"+LAB_INFO_PATH, na_rep='', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the required mappings.\n",
    "The custom dict and list are created from `05a_export_raw_info.ipynb` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_derived ['uid', 'label', 'units', 'category', 'notes']\n",
      "d_items ['uid', 'itemid', 'label', 'abbreviation', 'linksto', 'category', 'unitname', 'param_type', 'lownormalvalue', 'highnormalvalue']\n",
      "d_labinfos ['itemid', 'valueuom', 'valueuom_count', 'ref_range_lower', 'ref_range_lower_count', 'ref_range_upper', 'ref_range_upper_count']\n",
      "d_labitems ['uid', 'itemid', 'label', 'fluid', 'category', 'loinc_code']\n"
     ]
    }
   ],
   "source": [
    "# labitems = pd.read_csv(\"../../../\"+LAB_ITEM_PATH, sep='\\t', header=0)\n",
    "# labitems.fillna('None')\n",
    "\n",
    "d_derived = pd.read_csv(\"../../../\"+DERIVED_ITEM_PATH, sep='\\t', header=0)\n",
    "d_derived = d_derived.fillna('None')\n",
    "print('d_derived', d_derived.columns.to_list())\n",
    "\n",
    "d_items = pd.read_csv(\"../../../\"+CHART_ITEM_PATH, sep='\\t', header=0)\n",
    "d_items = d_items.fillna('None')\n",
    "print('d_items', d_items.columns.to_list())\n",
    "\n",
    "d_labinfos = pd.read_csv(\"../../../\"+LAB_INFO_PATH, sep='\\t', header=0)\n",
    "d_labinfos = d_labinfos.fillna('None')\n",
    "print('d_labinfos', d_labinfos.columns.to_list())\n",
    "\n",
    "d_labitems = pd.read_csv(\"../../../\"+LAB_ITEM_PATH, sep='\\t', header=0)\n",
    "d_labitems = d_labitems.fillna('None')\n",
    "print('d_labitems', d_labitems.columns.to_list())\n",
    "\n",
    "with open(\"../../../\" + TMP_CUSTOM_LIST, 'r') as f:\n",
    "    custom_icustays_list = json.load(f)\n",
    "\n",
    "with open(\"../../../\" + TMP_CUSTOM_DICT, 'r') as f:\n",
    "    custom_icustays_dict = json.load(f)\n",
    "\n",
    "\n",
    "def create_mappings(_id_mapping: dict):\n",
    "\n",
    "    id_mapping = {}\n",
    "    unit_mapping = {}\n",
    "    low_mapping = {}\n",
    "    high_mapping = {}\n",
    "    cat_mapping = {}\n",
    "\n",
    "    for k, v in _id_mapping.items():\n",
    "\n",
    "        id_mapping[v] = k\n",
    "\n",
    "        if k//100000 == 1:\n",
    "            unit_mapping[v] = d_derived[d_derived['uid']\n",
    "                                        == k]['units'].values[0]\n",
    "            low_mapping[v] = None  # TODO ADD THIS IN THE DERIVED TABLE?\n",
    "            high_mapping[v] = None  # TODO ADD THIS IN THE DERIVED TABLE?\n",
    "            cat_mapping[v] = d_derived[d_derived['uid']\n",
    "                                       == k]['category'].values[0]\n",
    "\n",
    "        elif k//200000 == 1:\n",
    "            unit_mapping[v] = d_items[d_items['uid']\n",
    "                                      == k]['unitname'].values[0]\n",
    "            low_mapping[v] = d_items[d_items['uid']\n",
    "                                     == k]['lownormalvalue'].values[0]\n",
    "            high_mapping[v] = d_items[d_items['uid']\n",
    "                                      == k]['highnormalvalue'].values[0]\n",
    "            cat_mapping[v] = d_items[d_items['uid'] == k]['category'].values[0]\n",
    "\n",
    "        elif k//500000 == 1:\n",
    "            cat_mapping[v] = d_labitems[d_labitems['uid']\n",
    "                                        == k]['category'].values[0]\n",
    "            unit_mapping[v] = None  # From db table\n",
    "            low_mapping[v] = None  # From db table\n",
    "            high_mapping[v] = None  # From db table\n",
    "\n",
    "        else:\n",
    "            unit_mapping[v] = None\n",
    "            low_mapping[v] = None\n",
    "            high_mapping[v] = None\n",
    "            cat_mapping[v] = None\n",
    "\n",
    "    return id_mapping, unit_mapping, low_mapping, high_mapping, cat_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data\n",
    "\n",
    "Currently the unit is taken from the original tables. A better solution is to include them in the concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:04<00:00, 663.22it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 663.30it/s]\n",
      "100%|██████████| 2688/2688 [00:04<00:00, 665.86it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 660.80it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 663.02it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 659.59it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 657.87it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 658.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting height data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for height : 35170\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'height']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:14<00:00, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added height entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def append_func(dt, df_row, cols):\n",
    "    dt.append(\n",
    "        uid=100001,\n",
    "        value=df_row['height'],\n",
    "        unit='cm',\n",
    "        category='General',\n",
    "        starttime=df_row['charttime'],\n",
    "    )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# [subject_id, stay_id, charttime, height]\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'height')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added height entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:03<00:00, 769.12it/s]\n",
      "100%|██████████| 2688/2688 [00:03<00:00, 767.91it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 762.93it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 763.55it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 758.29it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 762.92it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 755.93it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 753.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting weight_durations data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for weight_durations : 287155\n",
      "Column names : ['stay_id', 'starttime', 'endtime', 'weight', 'weight_type']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:27<00:00,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added weight entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def append_func(dt, df_row, col):\n",
    "    dt.append(\n",
    "        uid=100002,\n",
    "        value=df_row['weight'],\n",
    "        unit='kg',\n",
    "        category='General, ' + df_row['weight_type'],\n",
    "        starttime=df_row['starttime'],\n",
    "        endtime=df_row['endtime'],\n",
    "    )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['stay_id', 'starttime', 'endtime', 'weight', 'weight_type']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'weight_durations')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added weight entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:03<00:00, 879.77it/s]\n",
      "100%|██████████| 2688/2688 [00:03<00:00, 879.77it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 871.83it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 868.25it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 870.16it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 865.58it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 859.84it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 857.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting chemistry data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:52,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for chemistry : 3956323\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'albumin', 'globulin', 'total_protein', 'aniongap', 'bicarbonate', 'bun', 'calcium', 'chloride', 'creatinine', 'glucose', 'sodium', 'potassium', 'albumin_unit', 'globulin_unit', 'total_protein_unit', 'aniongap_unit', 'bicarbonate_unit', 'bun_unit', 'calcium_unit', 'chloride_unit', 'creatinine_unit', 'glucose_unit', 'sodium_unit', 'potassium_unit', 'albumin_lower', 'globulin_lower', 'total_protein_lower', 'aniongap_lower', 'bicarbonate_lower', 'bun_lower', 'calcium_lower', 'chloride_lower', 'creatinine_lower', 'glucose_lower', 'sodium_lower', 'potassium_lower', 'albumin_upper', 'globulin_upper', 'total_protein_upper', 'aniongap_upper', 'bicarbonate_upper', 'bun_upper', 'calcium_upper', 'chloride_upper', 'creatinine_upper', 'glucose_upper', 'sodium_upper', 'potassium_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [14:09<00:00, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chemistry (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    550862: 'albumin',\n",
    "    550930: 'globulin',\n",
    "    550976: 'total_protein',\n",
    "    550868: 'aniongap',\n",
    "    550882: 'bicarbonate',\n",
    "    551006: 'bun',\n",
    "    550893: 'calcium',\n",
    "    550902: 'chloride',\n",
    "    550912: 'creatinine',\n",
    "    550931: 'glucose',\n",
    "    550983: 'sodium',\n",
    "    550971: 'potassium',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=df_row[col+'_unit'],\n",
    "                lower_range=df_row[col+'_lower'],\n",
    "                upper_range=df_row[col+'_upper'],\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'albumin', 'globulin', 'total_protein', 'aniongap', 'bicarbonate', 'bun', 'calcium', 'chloride', 'creatinine', 'glucose', 'sodium', 'potassium']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'chemistry')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added chemistry (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting bg data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:52,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for bg : 561212\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen', 'specimen_unit', 'specimen_lower', 'specimen_upper', 'specimen_pred', 'specimen_prob', 'so2', 'so2_unit', 'so2_lower', 'so2_upper', 'po2', 'po2_unit', 'po2_lower', 'po2_upper', 'pco2', 'pco2_unit', 'pco2_lower', 'pco2_upper', 'fio2_chartevents', 'fio2', 'fio2_unit', 'fio2_lower', 'fio2_upper', 'aado2', 'aado2_unit', 'aado2_lower', 'aado2_upper', 'aado2_calc', 'pao2fio2ratio', 'ph', 'ph_unit', 'ph_lower', 'ph_upper', 'baseexcess', 'baseexcess_unit', 'baseexcess_lower', 'baseexcess_upper', 'bicarbonate', 'bicarbonate_unit', 'bicarbonate_lower', 'bicarbonate_upper', 'totalco2', 'totalco2_unit', 'totalco2_lower', 'totalco2_upper', 'hematocrit', 'hematocrit_unit', 'hematocrit_lower', 'hematocrit_upper', 'hemoglobin', 'hemoglobin_unit', 'hemoglobin_lower', 'hemoglobin_upper', 'carboxyhemoglobin', 'carboxyhemoglobin_unit', 'carboxyhemoglobin_lower', 'carboxyhemoglobin_upper', 'methemoglobin', 'methemoglobin_unit', 'methemoglobin_lower', 'methemoglobin_upper', 'chloride', 'chloride_unit', 'chloride_lower', 'chloride_upper', 'calcium', 'calcium_unit', 'calcium_lower', 'calcium_upper', 'temperature', 'temperature_unit', 'temperature_lower', 'temperature_upper', 'potassium', 'potassium_unit', 'potassium_lower', 'potassium_upper', 'sodium', 'sodium_unit', 'sodium_lower', 'sodium_upper', 'lactate', 'lactate_unit', 'lactate_lower', 'lactate_upper', 'glucose', 'glucose_unit', 'glucose_lower', 'glucose_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:45<00:00, 35.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added bg (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    552028: 'specimen',\n",
    "    550801: 'aado2',\n",
    "    550802: 'baseexcess',\n",
    "    550803: 'bicarbonate',\n",
    "    550804: 'totalco2',\n",
    "    550805: 'carboxyhemoglobin',\n",
    "    550806: 'chloride',\n",
    "    550808: 'calcium',\n",
    "    550809: 'glucose',\n",
    "    550810: 'hematocrit',\n",
    "    550811: 'hemoglobin',\n",
    "    550813: 'lactate',\n",
    "    550814: 'methemoglobin',\n",
    "    550816: 'fio2',\n",
    "    550817: 'so2',\n",
    "    550818: 'pco2',\n",
    "    550820: 'ph',\n",
    "    550821: 'po2',\n",
    "    550822: 'potassium',\n",
    "    550824: 'sodium',\n",
    "    550825: 'temperature',\n",
    "    223835: 'fio2_chartevents',\n",
    "    100038: 'pao2fio2ratio',  # nounit\n",
    "    100039: 'aado2_calc',\n",
    "    100040: 'specimen_pred',  # nounit\n",
    "    100041: 'specimen_prob',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "\n",
    "            if id_mapping[col]//100000 == 1:\n",
    "                unit = unit_mapping[col]\n",
    "                lower_range = low_mapping[col]\n",
    "                upper_range = high_mapping[col]\n",
    "\n",
    "                if id_mapping[col] == 100039:\n",
    "                    unit = df_row['aado2_unit'],\n",
    "                    lower_range = df_row['aado2_lower'],\n",
    "                    upper_range = df_row['aado2_upper'],\n",
    "\n",
    "            elif id_mapping[col]//100000 == 2:\n",
    "                unit = unit_mapping[col]\n",
    "                lower_range = low_mapping[col]\n",
    "                upper_range = high_mapping[col]\n",
    "\n",
    "            else:\n",
    "                unit = df_row[col+'_unit'],\n",
    "                lower_range = df_row[col+'_lower'],\n",
    "                upper_range = df_row[col+'_upper'],\n",
    "\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit,\n",
    "                lower_range=lower_range,\n",
    "                upper_range=upper_range,\n",
    "                category=cat_mapping[col],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "# count += 1\n",
    "# create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen', 'specimen_pred', 'specimen_prob', 'so2', 'po2', 'pco2', 'fio2_chartevents', 'fio2', 'aado2', 'aado2_calc', 'pao2fio2ratio', 'ph', 'baseexcess', 'bicarbonate', 'totalco2', 'hematocrit', 'hemoglobin', 'carboxyhemoglobin', 'methemoglobin', 'chloride', 'calcium', 'temperature', 'potassium', 'sodium', 'lactate', 'glucose']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'bg')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added bg (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:03<00:00, 836.01it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 833.60it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 831.48it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 833.92it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 832.28it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 834.78it/s]\n",
      "100%|██████████| 2688/2688 [00:03<00:00, 833.34it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 828.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting blood_differential data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:08,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for blood_differential : 3283493\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'wbc', 'wbc_unit', 'wbc_lower', 'wbc_upper', 'basophils_abs', 'basophils_abs_unit', 'basophils_abs_lower', 'basophils_abs_upper', 'eosinophils_abs', 'eosinophils_abs_unit', 'eosinophils_abs_lower', 'eosinophils_abs_upper', 'lymphocytes_abs', 'lymphocytes_abs_unit', 'lymphocytes_abs_lower', 'lymphocytes_abs_upper', 'monocytes_abs', 'monocytes_abs_unit', 'monocytes_abs_lower', 'monocytes_abs_upper', 'neutrophils_abs', 'neutrophils_abs_unit', 'neutrophils_abs_lower', 'neutrophils_abs_upper', 'basophils', 'basophils_unit', 'basophils_lower', 'basophils_upper', 'eosinophils', 'eosinophils_unit', 'eosinophils_lower', 'eosinophils_upper', 'lymphocytes', 'lymphocytes_unit', 'lymphocytes_lower', 'lymphocytes_upper', 'monocytes', 'monocytes_unit', 'monocytes_lower', 'monocytes_upper', 'neutrophils', 'neutrophils_unit', 'neutrophils_lower', 'neutrophils_upper', 'atypical_lymphocytes', 'atypical_lymphocytes_unit', 'atypical_lymphocytes_lower', 'atypical_lymphocytes_upper', 'bands', 'bands_unit', 'bands_lower', 'bands_upper', 'immature_granulocytes', 'immature_granulocytes_unit', 'immature_granulocytes_lower', 'immature_granulocytes_upper', 'metamyelocytes', 'metamyelocytes_unit', 'metamyelocytes_lower', 'metamyelocytes_upper', 'nrbc', 'nrbc_unit', 'nrbc_lower', 'nrbc_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [11:54<00:00, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added blood_differential (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# impute absolute count if percentage & WBC is available\n",
    "id_mapping = {\n",
    "    551146: 'basophils',\n",
    "    552069: 'basophils_abs',\n",
    "    551200: 'eosinophils',\n",
    "    551254: 'monocytes',\n",
    "    551256: 'neutrophils',\n",
    "    552075: 'neutrophils_abs',\n",
    "    551143: 'atypical_lymphocytes',\n",
    "    551144: 'bands',\n",
    "    552135: 'immature_granulocytes',\n",
    "    551251: 'metamyelocytes',\n",
    "    551257: 'nrbc',\n",
    "\n",
    "    100003: 'wbc',  # TODO: May need to split due to category.\n",
    "    100004: 'lymphocytes',\n",
    "    100005: 'eosinophils_abs',\n",
    "    100006: 'lymphocytes_abs',\n",
    "    100007: 'monocytes_abs',\n",
    "\n",
    "    # 51300: 'wbc',\n",
    "    # 51301: 'wbc',\n",
    "    # 51755: 'wbc',\n",
    "    # [51244, 51245]: lymphocytes\n",
    "    # [52073, 51199]: eosinophils_abs\n",
    "    # [51133, 52769]: lymphocytes_abs\n",
    "    # [52074, 51253]: monocytes_abs\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            if id_mapping[col]//100000 == 1:\n",
    "                unit = unit_mapping[col]\n",
    "                lower_range = low_mapping[col]\n",
    "                upper_range = high_mapping[col]\n",
    "\n",
    "                if id_mapping[col] == 100003:\n",
    "                    lower_range = df_row['wbc_lower'],\n",
    "                    upper_range = df_row['wbc_upper'],\n",
    "                elif id_mapping[col] == 100004:\n",
    "                    lower_range = df_row['lymphocytes_lower'],\n",
    "                    upper_range = df_row['lymphocytes_upper'],\n",
    "                elif id_mapping[col] == 100005:\n",
    "                    lower_range = df_row['eosinophils_abs_lower'],\n",
    "                    upper_range = df_row['eosinophils_abs_upper'],\n",
    "                elif id_mapping[col] == 100006:\n",
    "                    lower_range = df_row['lymphocytes_abs_lower'],\n",
    "                    upper_range = df_row['lymphocytes_abs_upper'],\n",
    "                elif id_mapping[col] == 100007:\n",
    "                    lower_range = df_row['monocytes_abs_lower'],\n",
    "                    upper_range = df_row['monocytes_abs_upper'],\n",
    "\n",
    "            else:\n",
    "                unit = df_row[col+'_unit'],\n",
    "                lower_range = df_row[col+'_lower'],\n",
    "                upper_range = df_row[col+'_upper'],\n",
    "\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit,\n",
    "                lower_range=lower_range,\n",
    "                upper_range=upper_range,\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'wbc', 'basophils_abs', 'eosinophils_abs', 'lymphocytes_abs', 'monocytes_abs', 'neutrophils_abs', 'basophils', 'eosinophils', 'lymphocytes', 'monocytes', 'neutrophils', 'atypical_lymphocytes', 'bands', 'immature_granulocytes', 'metamyelocytes', 'nrbc']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'blood_differential')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added blood_differential (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiac Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 911.99it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 897.87it/s]\n",
      "100%|██████████| 2688/2688 [00:03<00:00, 891.70it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 889.30it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 880.63it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 875.25it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 884.70it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 863.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting cardiac_marker data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for cardiac_marker : 430049\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'troponin_i', 'troponin_t', 'ck_mb', 'troponin_i_unit', 'troponin_t_unit', 'ck_mb_unit', 'troponin_i_lower', 'troponin_t_lower', 'ck_mb_lower', 'troponin_i_upper', 'troponin_t_upper', 'ck_mb_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:03<00:00, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added cardiac_marker (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    551002: 'troponin_i',\n",
    "    551003: 'troponin_t',\n",
    "    550911: 'ck_mb',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=df_row[col+'_unit'],\n",
    "                lower_range=df_row[col+'_lower'],\n",
    "                upper_range=df_row[col+'_upper'],\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'troponin_i', 'troponin_t', 'ck_mb']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'cardiac_marker')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added cardiac_marker (lab) entries.\")\n",
    "\n",
    "# hadm_list, sub_list = [], []\n",
    "# for chunk in tqdm(df_iter):\n",
    "#     num_entries += len(chunk)\n",
    "#     hadm_list += chunk['hadm_id'].tolist()\n",
    "#     sub_list += chunk['subject_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coagulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2688/2688 [00:04<00:00, 648.06it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 643.84it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 641.45it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 638.88it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 638.27it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 636.93it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 635.02it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 622.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting coagulation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:10,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for coagulation : 1594879\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'd_dimer', 'fibrinogen', 'thrombin', 'inr', 'pt', 'ptt', 'd_dimer_unit', 'fibrinogen_unit', 'thrombin_unit', 'inr_unit', 'pt_unit', 'ptt_unit', 'd_dimer_lower', 'fibrinogen_lower', 'thrombin_lower', 'inr_lower', 'pt_lower', 'ptt_lower', 'd_dimer_upper', 'fibrinogen_upper', 'thrombin_upper', 'inr_upper', 'pt_upper', 'ptt_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:52<00:00, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added coagulation (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    551196: 'd_dimer',\n",
    "    551214: 'fibrinogen',\n",
    "    551297: 'thrombin',\n",
    "    551237: 'inr',\n",
    "    551274: 'pt',\n",
    "    551275: 'ptt',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=df_row[col+'_unit'],\n",
    "                lower_range=df_row[col+'_lower'],\n",
    "                upper_range=df_row[col+'_upper'],\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'd_dimer', 'fibrinogen', 'thrombin', 'inr', 'pt', 'ptt']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'coagulation')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added coagulation (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete blood count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:03<00:00, 810.41it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 790.47it/s]\n",
      "100%|██████████| 2688/2688 [00:03<00:00, 792.33it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 788.04it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 788.10it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 781.35it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 785.62it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 778.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting complete_blood_count data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [01:25,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for complete_blood_count : 3492512\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'hematocrit', 'hemoglobin', 'mch', 'mchc', 'mcv', 'platelet', 'rbc', 'rdw', 'rdwsd', 'wbc', 'hematocrit_unit', 'hemoglobin_unit', 'mch_unit', 'mchc_unit', 'mcv_unit', 'platelet_unit', 'rbc_unit', 'rdw_unit', 'rdwsd_unit', 'wbc_unit', 'hematocrit_lower', 'hemoglobin_lower', 'mch_lower', 'mchc_lower', 'mcv_lower', 'platelet_lower', 'rbc_lower', 'rdw_lower', 'rdwsd_lower', 'wbc_lower', 'hematocrit_upper', 'hemoglobin_upper', 'mch_upper', 'mchc_upper', 'mcv_upper', 'platelet_upper', 'rbc_upper', 'rdw_upper', 'rdwsd_upper', 'wbc_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [13:15<00:00, 18.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added complete_blood_count (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    551221: 'hematocrit',\n",
    "    551222: 'hemoglobin',\n",
    "    551248: 'mch',\n",
    "    551249: 'mchc',\n",
    "    551250: 'mcv',\n",
    "    551265: 'platelet',\n",
    "    551279: 'rbc',\n",
    "    551277: 'rdw',\n",
    "    552159: 'rdwsd',\n",
    "    # 551301: 'wbc', # present in blood_differential\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=df_row[col+'_unit'],\n",
    "                lower_range=df_row[col+'_lower'],\n",
    "                upper_range=df_row[col+'_upper'],\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'hematocrit', 'hemoglobin', 'mch', 'mchc', 'mcv', 'platelet', 'rbc', 'rdw', 'rdwsd', 'wbc']\n",
    "df_iter, num_entries = get_db_table_as_df_ext(\n",
    "    'derived', 'complete_blood_count')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added complete_blood_count (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enzyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 1009.40it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 993.42it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 987.48it/s] \n",
      "100%|██████████| 2694/2694 [00:02<00:00, 989.73it/s] \n",
      "100%|██████████| 2688/2688 [00:02<00:00, 986.48it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 980.74it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 970.26it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 966.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting enzyme data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:24,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for enzyme : 1787236\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'alt', 'alp', 'ast', 'amylase', 'bilirubin_total', 'bilirubin_direct', 'bilirubin_indirect', 'ck_cpk', 'ck_mb', 'ggt', 'ld_ldh', 'alt_unit', 'alp_unit', 'ast_unit', 'amylase_unit', 'bilirubin_total_unit', 'bilirubin_direct_unit', 'bilirubin_indirect_unit', 'ck_cpk_unit', 'ck_mb_unit', 'ggt_unit', 'ld_ldh_unit', 'alt_lower', 'alp_lower', 'ast_lower', 'amylase_lower', 'bilirubin_total_lower', 'bilirubin_direct_lower', 'bilirubin_indirect_lower', 'ck_cpk_lower', 'ck_mb_lower', 'ggt_lower', 'ld_ldh_lower', 'alt_upper', 'alp_upper', 'ast_upper', 'amylase_upper', 'bilirubin_total_upper', 'bilirubin_direct_upper', 'bilirubin_indirect_upper', 'ck_cpk_upper', 'ck_mb_upper', 'ggt_upper', 'ld_ldh_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [04:49<00:00, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added enzyme (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    550861: 'alt',\n",
    "    550863: 'alp',\n",
    "    550878: 'ast',\n",
    "    550867: 'amylase',\n",
    "    550885: 'bilirubin_total',\n",
    "    550884: 'bilirubin_indirect',\n",
    "    550883: 'bilirubin_direct',\n",
    "    550910: 'ck_cpk',\n",
    "    550911: 'ck_mb',\n",
    "    550927: 'ggt',\n",
    "    550954: 'ld_ldh',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=df_row[col+'_unit'],\n",
    "                lower_range=df_row[col+'_lower'],\n",
    "                upper_range=df_row[col+'_upper'],\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'alt', 'alp', 'ast', 'amylase', 'bilirubin_total', 'bilirubin_direct', 'bilirubin_indirect', 'ck_cpk', 'ck_mb', 'ggt', 'ld_ldh']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'enzyme')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added enzyme (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inflamation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 1012.64it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 988.76it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 987.17it/s] \n",
      "100%|██████████| 2694/2694 [00:02<00:00, 983.03it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 986.62it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 981.79it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 973.35it/s] \n",
      "100%|██████████| 2694/2694 [00:02<00:00, 966.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting inflammation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for inflammation : 118290\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'crp', 'crp_unit', 'crp_lower', 'crp_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:13<00:00,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added inflammation (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    550889: 'crp',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=df_row[col+'_unit'],\n",
    "                lower_range=df_row[col+'_lower'],\n",
    "                upper_range=df_row[col+'_upper'],\n",
    "                category=cat_mapping[col],\n",
    "                specimen_id=df_row['specimen_id'],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'crp']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'inflammation')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added inflammation (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O2 delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 937.72it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 931.84it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 932.92it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 930.77it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 926.89it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 921.38it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 918.96it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 908.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting oxygen_delivery data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:01,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for oxygen_delivery : 829534\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'o2_flow', 'o2_flow_additional', 'o2_delivery_device_1', 'o2_delivery_device_2', 'o2_delivery_device_3', 'o2_delivery_device_4']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:58<00:00,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added oxygen_delivery (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    227287: 'o2_flow_additional',\n",
    "\n",
    "    100012: 'o2_flow',\n",
    "    100008: 'o2_delivery_device_1',\n",
    "    100009: 'o2_delivery_device_2',\n",
    "    100010: 'o2_delivery_device_3',\n",
    "    100011: 'o2_delivery_device_4',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit_mapping[col],\n",
    "                lower_range=low_mapping[col],\n",
    "                upper_range=high_mapping[col],\n",
    "                category=cat_mapping[col],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'stay_id', 'charttime', 'o2_flow', 'o2_flow_additional', 'o2_delivery_device_1', 'o2_delivery_device_2', 'o2_delivery_device_3', 'o2_delivery_device_4']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'oxygen_delivery')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added oxygen_delivery (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2688/2688 [00:02<00:00, 1003.54it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 970.44it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 976.15it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 970.84it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 975.84it/s] \n",
      "100%|██████████| 2694/2694 [00:02<00:00, 966.39it/s] \n",
      "100%|██████████| 2694/2694 [00:02<00:00, 968.59it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 964.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting rhythm data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:08,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for rhythm : 6184785\n",
      "Column names : ['subject_id', 'charttime', 'heart_rhythm', 'ectopy_type', 'ectopy_frequency', 'ectopy_type_secondary', 'ectopy_frequency_secondary']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [28:19<00:00, 21.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added rhythm (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    220048: 'heart_rhythm',\n",
    "    224650: 'ectopy_type',\n",
    "    224651: 'ectopy_frequency',\n",
    "    226479: 'ectopy_type_secondary',\n",
    "    226480: 'ectopy_frequency_secondary',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit_mapping[col],\n",
    "                lower_range=low_mapping[col],\n",
    "                upper_range=high_mapping[col],\n",
    "                category=cat_mapping[col],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'charttime', 'heart_rhythm', 'ectopy_type', 'ectopy_frequency', 'ectopy_type_secondary', 'ectopy_frequency_secondary']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'rhythm')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added rhythm (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urine Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 1000.78it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 986.44it/s] \n",
      "100%|██████████| 2694/2694 [00:02<00:00, 985.12it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 984.18it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 970.00it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 978.69it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 963.08it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 959.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting urine_output data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:04, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for urine_output : 3497267\n",
      "Column names : ['stay_id', 'charttime', 'urineoutput']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [06:10<00:00,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added urine_output (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def append_func(dt, df_row, cols):\n",
    "    dt.append(\n",
    "        uid=100013,\n",
    "        value=df_row['urineoutput'],\n",
    "        unit='mL',\n",
    "        category='Output',\n",
    "        starttime=df_row['charttime'],\n",
    "    )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['stay_id', 'charttime', 'urineoutput']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'urine_output')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added urine_output (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urine Output Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 987.26it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 966.47it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 966.99it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 961.49it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 960.83it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 965.67it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 950.25it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 941.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting urine_output_rate data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:22,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for urine_output_rate : 3497266\n",
      "Column names : ['stay_id', 'charttime', 'weight', 'uo', 'urineoutput_6hr', 'urineoutput_12hr', 'urineoutput_24hr', 'uo_mlkghr_6hr', 'uo_mlkghr_12hr', 'uo_mlkghr_24hr', 'uo_tm_6hr', 'uo_tm_12hr', 'uo_tm_24hr']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:32<00:00, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added urine_output_rate (derived) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -- attempt to calculate urine output per hour\n",
    "# -- rate/hour is the interpretable measure of kidney function\n",
    "# -- though it is difficult to estimate from aperiodic point measures\n",
    "# -- first we get the earliest heart rate documented for the stay\n",
    "id_mapping = {\n",
    "    # 100013: 'uo', present in previous table.\n",
    "    100014: 'urineoutput_6hr',  # output within 6hr (floor)\n",
    "    100015: 'urineoutput_12hr',\n",
    "    100016: 'urineoutput_24hr',\n",
    "    100017: 'uo_mlkghr_6hr',  # (urineoutput_6hr/weight/uo_tm_6hr)\n",
    "    100018: 'uo_mlkghr_12hr',\n",
    "    100019: 'uo_mlkghr_24hr',\n",
    "    100020: 'uo_tm_6hr',  # time from last uo measurement within 6hr (floor)\n",
    "    100021: 'uo_tm_12hr',\n",
    "    100022: 'uo_tm_24hr',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit_mapping[col],\n",
    "                lower_range=low_mapping[col],\n",
    "                upper_range=high_mapping[col],\n",
    "                category=cat_mapping[col],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['stay_id', 'charttime', 'weight', 'uo', 'urineoutput_6hr', 'urineoutput_12hr', 'urineoutput_24hr', 'uo_mlkghr_6hr', 'uo_mlkghr_12hr', 'uo_mlkghr_24hr', 'uo_tm_6hr', 'uo_tm_12hr', 'uo_tm_24hr']\n",
    "df_iter, num_entries = get_db_table_as_df_ext(\n",
    "    'derived', 'urine_output_rate', _chunk=30000)\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added urine_output_rate (derived) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vent settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 1022.10it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 1013.40it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1008.24it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1005.54it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 994.89it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 998.71it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 987.40it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 987.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting ventilator_setting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:03,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for ventilator_setting : 1067028\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'respiratory_rate_set', 'respiratory_rate_total', 'respiratory_rate_spontaneous', 'minute_volume', 'tidal_volume_set', 'tidal_volume_observed', 'tidal_volume_spontaneous', 'plateau_pressure', 'peep', 'fio2', 'ventilator_mode', 'ventilator_mode_hamilton', 'ventilator_type']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:47<00:00,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added ventilator_setting (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    224688: 'respiratory_rate_set',\n",
    "    224690: 'respiratory_rate_total',\n",
    "    224689: 'respiratory_rate_spontaneous',\n",
    "    224687: 'minute_volume',\n",
    "    224684: 'tidal_volume_set',\n",
    "    224685: 'tidal_volume_observed',\n",
    "    224686: 'tidal_volume_spontaneous',\n",
    "    224696: 'plateau_pressure',\n",
    "    100023: 'peep',\n",
    "    # 223835: 'fio2',  # same as fio2_chartevents\n",
    "    223849: 'ventilator_mode',\n",
    "    229314: 'ventilator_mode_hamilton',\n",
    "    223848: 'ventilator_type',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit_mapping[col],\n",
    "                lower_range=low_mapping[col],\n",
    "                upper_range=high_mapping[col],\n",
    "                category=cat_mapping[col],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'stay_id', 'charttime', 'respiratory_rate_set', 'respiratory_rate_total', 'respiratory_rate_spontaneous', 'minute_volume', 'tidal_volume_set', 'tidal_volume_observed', 'tidal_volume_spontaneous', 'plateau_pressure', 'peep', 'fio2', 'ventilator_mode', 'ventilator_mode_hamilton', 'ventilator_type']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'ventilator_setting')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added ventilator_setting (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vital Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 1052.50it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1045.58it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1034.73it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 1041.94it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1033.84it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1036.97it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1037.08it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1026.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting vitalsign data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:44,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for vitalsign : 10249430\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'heart_rate', 'sbp', 'dbp', 'mbp', 'sbp_ni', 'dbp_ni', 'mbp_ni', 'resp_rate', 'temperature', 'temperature_site', 'spo2', 'glucose']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [57:27<00:00, 265.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added vitalsign (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    220045: 'heart_rate',\n",
    "    100024: 'sbp',\n",
    "    100025: 'dbp',\n",
    "    100026: 'mbp',\n",
    "    220179: 'sbp_ni',\n",
    "    220180: 'dbp_ni',\n",
    "    220181: 'mbp_ni',\n",
    "    100027: 'resp_rate',\n",
    "    100028: 'temperature',\n",
    "    224642: 'temperature_site',\n",
    "    220277: 'spo2',\n",
    "    100029: 'glucose_chartevents',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "\n",
    "# ['subject_id', 'stay_id', 'charttime', 'heart_rate', 'sbp', 'dbp', 'mbp', 'sbp_ni', 'dbp_ni', 'mbp_ni', 'resp_rate', 'temperature', 'temperature_site', 'spo2', 'glucose']\n",
    "df_iter, num_entries = get_db_table_as_df_ext(\n",
    "    'derived', 'vitalsign', _chunk=100000)\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    stay_id_mem = -1\n",
    "    save_path = None\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if stay_id_mem == -1:\n",
    "            stay_id_mem = df_row['stay_id']\n",
    "            save_path = get_data_save_path(STRUCTURED_EXPORT_DIR+str(count),\n",
    "                                           df_row['stay_id'])\n",
    "            dt.data = load_data_dsv(save_path)\n",
    "\n",
    "        elif df_row['stay_id'] != stay_id_mem:\n",
    "            save_path = get_data_save_path(STRUCTURED_EXPORT_DIR+str(count),\n",
    "                                           stay_id_mem)\n",
    "            save_data_dsv_ext(save_path, dt.data)\n",
    "            stay_id_mem = df_row['stay_id']\n",
    "            save_path = get_data_save_path(STRUCTURED_EXPORT_DIR+str(count),\n",
    "                                           df_row['stay_id'])\n",
    "            dt.data = load_data_dsv(save_path)\n",
    "\n",
    "        for col in df.columns.tolist():\n",
    "            if col in id_mapping:\n",
    "                dt.append(\n",
    "                    uid=id_mapping[col],\n",
    "                    value=df_row[col],\n",
    "                    unit=unit_mapping[col],\n",
    "                    lower_range=low_mapping[col],\n",
    "                    upper_range=high_mapping[col],\n",
    "                    category=cat_mapping[col],\n",
    "                    starttime=df_row['charttime'],\n",
    "                )\n",
    "\n",
    "    save_data_dsv_ext(save_path, dt.data)\n",
    "\n",
    "# parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "\n",
    "\n",
    "sort_list = ['subject_id', 'hadm_id', 'stay_id',\n",
    "             'charttime', 'starttime', 'endtime', ]\n",
    "# mem_flag, df_mem = False, pd.DataFrame()\n",
    "for df in tqdm(df_iter, total=num_entries):\n",
    "\n",
    "    if 'stay_id' in df.columns.tolist():\n",
    "        df = df[df.stay_id.isin(custom_icustays_list)]\n",
    "        # df_mem = pd.concat([df_mem, df]) if mem_flag else df\n",
    "        # uc = df_mem.nunique(axis=1)\n",
    "        # if uc < MP_NUM_PROCESSES:\n",
    "        #     mem_flag = True\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     df = df_mem\n",
    "        #     mem_flag, df_mem = False, pd.DataFrame()\n",
    "\n",
    "    df = df.sort_values(\n",
    "        by=[i for i in sort_list if i in df.columns.tolist()])\n",
    "    dfs = split_df(df, MP_NUM_PROCESSES)\n",
    "    parallel_processing(func, MP_NUM_PROCESSES, dfs)\n",
    "\n",
    "\n",
    "print(\"Added vitalsign (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antibiotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (query_schema_core,\n",
    "#  query_schema_hosp,\n",
    "#  query_schema_icu,\n",
    "#  query_schema_derived,\n",
    "#  conn) = connect_db()\n",
    "\n",
    "# # ['subject_id', 'hadm_id', 'stay_id', 'antibiotic', 'route', 'starttime', 'stoptime']\n",
    "# df = get_database_table_as_dataframe(conn, query_schema_derived, 'antibiotic')\n",
    "# df = df[df.stay_id.isin(custom_icustays_list)]\n",
    "\n",
    "\n",
    "# def func(dfs, pid):\n",
    "\n",
    "#\n",
    "#\n",
    "\n",
    "#     df = dfs[0]\n",
    "#     it = InfoTable()\n",
    "#     dt = DataTable()\n",
    "#     for df_i in df.iterrows():\n",
    "#         df_row = df_i[1]\n",
    "#         dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, df_row['stay_id'])\n",
    "#         dt.append(\n",
    "#             uid=100030,\n",
    "#             value=df_row['antibiotic'],\n",
    "#             category=df_row['route'],\n",
    "#             starttime=df_row['starttime'],\n",
    "#             endtime=df_row['stoptime'],\n",
    "#         )\n",
    "#         save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "#                       df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "# dfs = split_df(df, MP_NUM_PROCESSES)\n",
    "# parallel_processing(func, MP_NUM_PROCESSES, dfs)\n",
    "\n",
    "# print(\"Added antibiotic (hosp.prescriptions) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:02<00:00, 1079.15it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1074.99it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1064.84it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1062.09it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1065.17it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1058.13it/s]\n",
      "100%|██████████| 2688/2688 [00:02<00:00, 1051.37it/s]\n",
      "100%|██████████| 2694/2694 [00:02<00:00, 1049.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting inputevents data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for inputevents : 782373\n",
      "Column names : ['subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'storetime', 'itemid', 'amount', 'amountuom', 'rate', 'rateuom', 'orderid', 'linkorderid', 'ordercategoryname', 'secondaryordercategoryname', 'ordercomponenttypedescription', 'ordercategorydescription', 'patientweight', 'totalamount', 'totalamountuom', 'isopenbag', 'continueinnextdept', 'cancelreason', 'statusdescription', 'originalamount', 'originalrate']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added (medication) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "med_ids = [\n",
    "    220995,  # Sodium Bicarbonate 8.4%\n",
    "    221794,  # Furosemide (Lasix) **\n",
    "    228340,  # Furosemide (Lasix) 250/50 **\n",
    "    # 100037,  # Furosemide (Lasix)\n",
    "    221986,  # Milrinone\n",
    "    229068,  # Protamine sulfate\n",
    "    229639,  # Bumetanide (Bumex)\n",
    "\n",
    "    221653,  # Dobutamine\n",
    "    221662,  # Dopamine\n",
    "    221289,  # Epinephrine\n",
    "    229617,  # Epinephrine. ~145 entries only\n",
    "    # 100036,  # Epinephrine\n",
    "    221906,  # Norepinephrine\n",
    "    221749,  # Phenylephrine\n",
    "    222315,  # Vasopressin\n",
    "]\n",
    "id_mapping = {\n",
    "    221794: 100037,\n",
    "    228340: 100037,\n",
    "    221289: 100036,\n",
    "    229617: 100036,\n",
    "}\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    uid = df_row['itemid']\n",
    "    dt.append(\n",
    "        uid=id_mapping[uid] if uid in id_mapping else uid,\n",
    "        value=df_row['amount'],\n",
    "        unit=df_row['amountuom'],\n",
    "        rate=df_row['rate'],\n",
    "        rate_unit=df_row['rateuom'],\n",
    "        category='Medication',\n",
    "        starttime=df_row['starttime'],\n",
    "        endtime=df_row['endtime'],\n",
    "    )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "\n",
    "(query_schema_core,\n",
    " query_schema_hosp,\n",
    " query_schema_icu,\n",
    " query_schema_derived,\n",
    " conn) = connect_db()\n",
    "\n",
    "df_iter, num_entries = get_database_table_as_dataframe(\n",
    "    conn, query_schema_icu, 'inputevents',\n",
    "    _filter_col='itemid',\n",
    "    _filter_col_val=tuple(med_ids),\n",
    "    _chunk_size=10000*MP_NUM_PROCESSES)\n",
    "num_entries = math.ceil(num_entries / (10000*MP_NUM_PROCESSES))\n",
    "\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added (medication) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDIGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:03<00:00, 680.95it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 679.40it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 675.48it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 678.52it/s]\n",
      "100%|██████████| 2688/2688 [00:03<00:00, 676.85it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 675.83it/s]\n",
      "100%|██████████| 2694/2694 [00:03<00:00, 677.34it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 672.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting kdigo_stages data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:18,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for kdigo_stages : 4111003\n",
      "Column names : ['subject_id', 'hadm_id', 'stay_id', 'charttime', 'creat_low_past_7day', 'creat_low_past_48hr', 'creat', 'aki_stage_creat', 'uo_rt_6hr', 'uo_rt_12hr', 'uo_rt_24hr', 'aki_stage_uo', 'aki_stage']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [11:19<00:00, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added kdigo_stages (derived) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    100031: 'creat_low_past_48hr',\n",
    "    100032: 'creat_low_past_7day',\n",
    "    100033: 'aki_stage_creat',\n",
    "    100034: 'aki_stage_uo',\n",
    "    100035: 'aki_stage',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "\n",
    "def append_func(dt, df_row, df_cols):\n",
    "    for col in df_cols:\n",
    "        if col in id_mapping:\n",
    "            dt.append(\n",
    "                uid=id_mapping[col],\n",
    "                value=df_row[col],\n",
    "                unit=unit_mapping[col],\n",
    "                lower_range=low_mapping[col],\n",
    "                upper_range=high_mapping[col],\n",
    "                category=cat_mapping[col],\n",
    "                starttime=df_row['charttime'],\n",
    "            )\n",
    "    return dt\n",
    "\n",
    "\n",
    "count += 1\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR+str(count), custom_icustays_list)\n",
    "# ['subject_id', 'hadm_id', 'stay_id', 'charttime', 'creat_low_past_7day', 'creat_low_past_48hr', 'creat', 'aki_stage_creat', 'uo_rt_6hr', 'uo_rt_12hr', 'uo_rt_24hr', 'aki_stage_uo', 'aki_stage']\n",
    "df_iter, num_entries = get_db_table_as_df_ext('derived', 'kdigo_stages')\n",
    "func = export_func_factory(append_func, STRUCTURED_EXPORT_DIR+str(count))\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added kdigo_stages (derived) entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2688/2688 [00:04<00:00, 585.70it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 580.19it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 580.80it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 580.82it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 579.57it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 574.86it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 578.59it/s]\n",
      "100%|██████████| 2694/2694 [00:04<00:00, 572.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2688/2688 [08:17<00:00,  5.40it/s]\n",
      "100%|██████████| 2694/2694 [08:18<00:00,  5.40it/s]\n",
      "100%|██████████| 2694/2694 [08:18<00:00,  5.40it/s]\n",
      "100%|██████████| 2694/2694 [08:20<00:00,  5.39it/s]\n",
      "100%|██████████| 2694/2694 [08:20<00:00,  5.38it/s]\n",
      "100%|██████████| 2694/2694 [08:21<00:00,  5.37it/s]\n",
      "100%|██████████| 2694/2694 [08:22<00:00,  5.36it/s]\n",
      "100%|██████████| 2694/2694 [08:23<00:00,  5.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(files, pid):\n",
    "\n",
    "    parent_dir, main_folder = os.path.split(STRUCTURED_EXPORT_DIR)\n",
    "    folders = [os.path.join(parent_dir, i)\n",
    "               for i in os.listdir(parent_dir) if i != main_folder]\n",
    "\n",
    "    for f in tqdm(files):\n",
    "        main_path = os.path.join(STRUCTURED_EXPORT_DIR, f)\n",
    "        df = pd.read_csv(main_path, sep='$')\n",
    "\n",
    "        for folder in folders:\n",
    "            path = os.path.join(folder, f)\n",
    "            df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        sort_list = ['starttime', 'uid']\n",
    "        df = df.sort_values(by=sort_list)\n",
    "\n",
    "        df.to_csv(main_path, na_rep='', sep='$', index=False)\n",
    "\n",
    "\n",
    "create_dummy_files(STRUCTURED_EXPORT_DIR, custom_icustays_list)\n",
    "data_files = [i for i in os.listdir(STRUCTURED_EXPORT_DIR) if 'data' in i]\n",
    "parallel_processing(func, MP_NUM_PROCESSES, data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
