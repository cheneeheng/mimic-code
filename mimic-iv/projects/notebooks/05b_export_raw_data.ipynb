{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exports raw data from mimic-iv database\n",
    "\n",
    "Only the following care unit patients are exported:\n",
    "- Coronary Care unit (CCU)\n",
    "- Cardiac Vascular Intensive Care unit (CVICU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.utils import *\n",
    "from projects.common import *\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool, RLock\n",
    "from configobj import ConfigObj\n",
    "import numpy as np\n",
    "import getpass\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n"
     ]
    }
   ],
   "source": [
    "def connect_db():\n",
    "    db_dir = os.path.abspath('') + \"/../../../db\"\n",
    "    return connect_to_database(db_dir)\n",
    "\n",
    "\n",
    "connect_db()\n",
    "\n",
    "# def merge_lab_df(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "#     target_cols = ['subject_id', 'hadm_id', 'charttime', 'specimen_id']\n",
    "#     df1 = df1.sort_values(target_cols)\n",
    "#     df2 = df2.sort_values(target_cols)\n",
    "#     df2 = df2.loc[:, ~df2.columns.isin(target_cols)]\n",
    "#     return pd.concat([df1, df2], axis=1)\n",
    "\n",
    "\n",
    "def create_dummy_files_func(export_dir, _custom_icustays_list, pid):\n",
    "    for icustay_id in _custom_icustays_list:\n",
    "        # if icustay_id != 39060235:\n",
    "        #     continue\n",
    "        assert not os.path.exists(os.path.join(\n",
    "            export_dir, 'data_'+str(icustay_id)+'.dsv'))\n",
    "        save_data_dsv(export_dir, icustay_id,\n",
    "                      pd.DataFrame(DataTable().data))\n",
    "\n",
    "\n",
    "def create_dummy_files(export_dir: str, _custom_icustays_list: list):\n",
    "    \"\"\" Create empty dummy .dsv files.\"\"\"\n",
    "    parallel_processing(create_dummy_files_func, MP_NUM_PROCESSES,\n",
    "                        export_dir, _custom_icustays_list)\n",
    "    print(\"Created dummy .dsv files.\")\n",
    "\n",
    "\n",
    "def get_database_table_as_dataframe_ext(_schema_type: str, _table: str,\n",
    "                                        _chunk: int = 10000):\n",
    "    \"\"\"Wrapper for generating dataframe from the db. \"\"\"\n",
    "    (query_schema_core,\n",
    "     query_schema_hosp,\n",
    "     query_schema_icu,\n",
    "     query_schema_derived,\n",
    "     conn) = connect_db()\n",
    "\n",
    "    if _schema_type == 'core':\n",
    "        _query_schema = query_schema_core\n",
    "    if _schema_type == 'hosp':\n",
    "        _query_schema = query_schema_hosp\n",
    "    if _schema_type == 'icu':\n",
    "        _query_schema = query_schema_icu\n",
    "    if _schema_type == 'derived':\n",
    "        _query_schema = query_schema_derived\n",
    "    else:\n",
    "        _query_schema = None\n",
    "\n",
    "    df_iter, num_entries = get_database_table_as_dataframe(\n",
    "        conn, _query_schema, _table, _chunk_size=_chunk*MP_NUM_PROCESSES)\n",
    "    num_entries = math.ceil(num_entries / (_chunk*MP_NUM_PROCESSES))\n",
    "    return df_iter, num_entries\n",
    "\n",
    "\n",
    "def split_df(df: pd.DataFrame, num_processes: int = 8):\n",
    "    interval = math.ceil(len(df)/num_processes)\n",
    "    dfs = [df.iloc[interval*i:interval*(i+1)]\n",
    "           for i in range((num_processes-1))]\n",
    "    dfs += [df.iloc[interval*(num_processes-1):]]\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def parallel_processing_ext(_func,\n",
    "                            _df_iter,\n",
    "                            _num_entries: int,\n",
    "                            _custom_icustays_list: list):\n",
    "    \"\"\"Wrapper for parallel processing. Sorts the dataframe based on \n",
    "    `sort_list` before running the `func`.\n",
    "\n",
    "    TODO: df should be splitted up based on `stay_id`, i.e. where all \n",
    "    the `stay_id` are assigned to the same process. If not may cause reading \n",
    "    error because this id determines which dsv file to read from. The current \n",
    "    hack is to create a large enough df chunk so that this error situation \n",
    "    will not occur.\n",
    "    \"\"\"\n",
    "    sort_list = ['subject_id', 'hadm_id', 'stay_id',\n",
    "                 'charttime', 'starttime', 'endtime', ]\n",
    "    for df in tqdm(_df_iter, total=_num_entries):\n",
    "        if 'stay_id' in df.columns.tolist():\n",
    "            df = df[df.stay_id.isin(_custom_icustays_list)]\n",
    "        df = df.sort_values(\n",
    "            by=[i for i in sort_list if i in df.columns.tolist()])\n",
    "        dfs = split_df(df, MP_NUM_PROCESSES)\n",
    "        parallel_processing(_func, MP_NUM_PROCESSES, dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save labevents_info table from db.\n",
    "# (_, _, _, query_schema_derived, conn) = connect_db()\n",
    "# df = get_database_table_as_dataframe(\n",
    "#     conn, query_schema_derived, 'labevents_info')\n",
    "# df = df.sort_values('itemid')\n",
    "# df.to_csv(\"../../../\"+LAB_INFO_PATH, na_rep='', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the required mappings.\n",
    "The custom dict and list are created from `05a_export_raw_info.ipynb` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_derived ['uid', 'label', 'units', 'category', 'notes']\n",
      "d_items ['uid', 'itemid', 'label', 'abbreviation', 'linksto', 'category', 'unitname', 'param_type', 'lownormalvalue', 'highnormalvalue']\n",
      "d_labinfos ['itemid', 'valueuom', 'valueuom_count', 'ref_range_lower', 'ref_range_lower_count', 'ref_range_upper', 'ref_range_upper_count']\n",
      "d_labitems ['uid', 'itemid', 'label', 'fluid', 'category', 'loinc_code']\n"
     ]
    }
   ],
   "source": [
    "# labitems = pd.read_csv(\"../../../\"+LAB_ITEM_PATH, sep='\\t', header=0)\n",
    "# labitems.fillna('None')\n",
    "\n",
    "d_derived = pd.read_csv(\"../../../\"+DERIVED_ITEM_PATH, sep='\\t', header=0)\n",
    "d_derived = d_derived.fillna('None')\n",
    "print('d_derived', d_derived.columns.to_list())\n",
    "\n",
    "d_items = pd.read_csv(\"../../../\"+CHART_ITEM_PATH, sep='\\t', header=0)\n",
    "d_items = d_items.fillna('None')\n",
    "print('d_items', d_items.columns.to_list())\n",
    "\n",
    "d_labinfos = pd.read_csv(\"../../../\"+LAB_INFO_PATH, sep='\\t', header=0)\n",
    "d_labinfos = d_labinfos.fillna('None')\n",
    "print('d_labinfos', d_labinfos.columns.to_list())\n",
    "\n",
    "d_labitems = pd.read_csv(\"../../../\"+LAB_ITEM_PATH, sep='\\t', header=0)\n",
    "d_labitems = d_labitems.fillna('None')\n",
    "print('d_labitems', d_labitems.columns.to_list())\n",
    "\n",
    "with open(\"../../../\" + TMP_CUSTOM_LIST, 'r') as f:\n",
    "    custom_icustays_list = json.load(f)\n",
    "\n",
    "with open(\"../../../\" + TMP_CUSTOM_DICT, 'r') as f:\n",
    "    custom_icustays_dict = json.load(f)\n",
    "\n",
    "\n",
    "def create_mappings(_id_mapping: dict):\n",
    "\n",
    "    id_mapping = {}\n",
    "    unit_mapping = {}\n",
    "    low_mapping = {}\n",
    "    high_mapping = {}\n",
    "    cat_mapping = {}\n",
    "\n",
    "    for k, v in _id_mapping.items():\n",
    "\n",
    "        id_mapping[v] = k\n",
    "\n",
    "        if k//100000 == 1:\n",
    "            unit_mapping[v] = d_derived[d_derived['uid'] == k]['units'].values[0]\n",
    "            low_mapping[v] = None  # TODO ADD THIS IN THE DERIVED TABLE?\n",
    "            high_mapping[v] = None  # TODO ADD THIS IN THE DERIVED TABLE?\n",
    "            cat_mapping[v] = d_derived[d_derived['uid'] == k]['category'].values[0]\n",
    "\n",
    "        elif k//200000 == 1:\n",
    "            unit_mapping[v] = d_items[d_items['uid'] == k]['unitname'].values[0]\n",
    "            low_mapping[v] = d_items[d_items['uid'] == k]['lownormalvalue'].values[0]\n",
    "            high_mapping[v] = d_items[d_items['uid'] == k]['highnormalvalue'].values[0]\n",
    "            cat_mapping[v] = d_items[d_items['uid'] == k]['category'].values[0]\n",
    "\n",
    "        elif k//500000 == 1:\n",
    "            cat_mapping[v] = d_labitems[d_labitems['uid'] == k]['category'].values[0]\n",
    "            unit_mapping[v] = None  # From db table\n",
    "            low_mapping[v] = None  # From db table\n",
    "            high_mapping[v] = None  # From db table\n",
    "\n",
    "        else:\n",
    "            unit_mapping[v] = None\n",
    "            low_mapping[v] = None\n",
    "            high_mapping[v] = None\n",
    "            cat_mapping[v] = None\n",
    "\n",
    "    return id_mapping, unit_mapping, low_mapping, high_mapping, cat_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks the labevents data.\n",
    "This is to check whether there are duplicates in the units and upper/lower boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_lab_itemid = {\n",
    "#     50862: 'albumin',\n",
    "#     50930: 'globulin',\n",
    "#     50976: 'total_protein',\n",
    "#     50868: 'aniongap',\n",
    "#     50882: 'bicarbonate',\n",
    "#     51006: 'bun',\n",
    "#     50893: 'calcium',\n",
    "#     50902: 'chloride',\n",
    "#     50912: 'creatinine',\n",
    "#     50931: 'glucose',\n",
    "#     50983: 'sodium',\n",
    "#     50971: 'potassium',\n",
    "\n",
    "#     52028: 'specimen',\n",
    "#     50801: 'aado2',\n",
    "#     50802: 'baseexcess',\n",
    "#     50803: 'bicarbonate',\n",
    "#     50804: 'totalco2',\n",
    "#     50805: 'carboxyhemoglobin',\n",
    "#     50806: 'chloride',\n",
    "#     50808: 'calcium',\n",
    "#     50809: 'glucose',\n",
    "#     50810: 'hematocrit',\n",
    "#     50811: 'hemoglobin',\n",
    "#     50813: 'lactate',\n",
    "#     50814: 'methemoglobin',\n",
    "#     50816: 'fio2',\n",
    "#     50817: 'so2',\n",
    "#     50818: 'pco2',\n",
    "#     50820: 'ph',\n",
    "#     50821: 'po2',\n",
    "#     50822: 'potassium',\n",
    "#     50824: 'sodium',\n",
    "#     50825: 'temperature',\n",
    "#     # 223835: 'fio2_chartevents',\n",
    "#     # 100038: 'pao2fio2ratio',  # nounit\n",
    "#     # 100039: 'aado2_calc',\n",
    "#     # 100040: 'specimen_pred',  # nounit\n",
    "#     # 100041: 'specimen_prob',\n",
    "\n",
    "#     51146: 'basophils',\n",
    "#     52069: 'basophils_abs',\n",
    "#     51200: 'eosinophils',\n",
    "#     51254: 'monocytes',\n",
    "#     51256: 'neutrophils',\n",
    "#     52075: 'neutrophils_abs',\n",
    "#     51143: 'atypical_lymphocytes',\n",
    "#     51144: 'bands',\n",
    "#     52135: 'immature_granulocytes',\n",
    "#     51251: 'metamyelocytes',\n",
    "#     51257: 'nrbc',\n",
    "#     # 51300: 'wbc',  # Has None as unit.\n",
    "#     # 51301: 'wbc',  # Has None as unit.\n",
    "#     # 51755: 'wbc',\n",
    "#     # 100003: 'wbc',  # TODO: May need to split due to category.\n",
    "#     # 100004: 'lymphocytes',\n",
    "#     # 100005: 'eosinophils_abs',  # Has None as unit.\n",
    "#     # 100006: 'lymphocytes_abs',  # Has None as unit.\n",
    "#     # 100007: 'monocytes_abs',  # Has None as unit.\n",
    "\n",
    "#     51002: 'troponin_i',\n",
    "#     51003: 'troponin_t',\n",
    "#     50911: 'ck_mb',\n",
    "\n",
    "#     51196: 'd_dimer',\n",
    "#     51214: 'fibrinogen',\n",
    "#     51297: 'thrombin',\n",
    "#     51237: 'inr',\n",
    "#     51274: 'pt',\n",
    "#     51275: 'ptt',\n",
    "\n",
    "#     51221: 'hematocrit',\n",
    "#     51222: 'hemoglobin',\n",
    "#     51248: 'mch',\n",
    "#     51249: 'mchc',\n",
    "#     51250: 'mcv',\n",
    "#     51265: 'platelet',\n",
    "#     51279: 'rbc',\n",
    "#     51277: 'rdw',\n",
    "#     52159: 'rdwsd',\n",
    "#     # 51301: 'wbc', # present in blood_differential\n",
    "\n",
    "#     50861: 'alt',\n",
    "#     50863: 'alp',\n",
    "#     50878: 'ast',\n",
    "#     50867: 'amylase',\n",
    "#     50885: 'bilirubin_total',\n",
    "#     50884: 'bilirubin_indirect',\n",
    "#     50883: 'bilirubin_direct',\n",
    "#     50910: 'ck_cpk',\n",
    "#     50911: 'ck_mb',\n",
    "#     50927: 'ggt',\n",
    "#     50954: 'ld_ldh',\n",
    "\n",
    "#     50889: 'crp',\n",
    "\n",
    "# }\n",
    "\n",
    "# target_lab_itemid = target_lab_itemid.keys()\n",
    "\n",
    "# d_labinfos = pd.read_csv(\"../../../\"+LAB_INFO_PATH, sep='\\t', header=0)\n",
    "# d_labinfos = d_labinfos.fillna('None')\n",
    "# print('d_labinfos', d_labinfos.columns.to_list())\n",
    "\n",
    "\n",
    "# print(\"Checking valueuom_count\")\n",
    "# for i in target_lab_itemid:\n",
    "#     if (d_labinfos[d_labinfos['itemid'] == i]['valueuom_count'] > 1).any():\n",
    "#         print(i)\n",
    "\n",
    "\n",
    "# print(\"Checking ref_range_lower_count\")\n",
    "# for i in target_lab_itemid:\n",
    "#     if (d_labinfos[d_labinfos['itemid'] == i]['ref_range_lower_count'] > 1).any():\n",
    "#         print(i, d_labinfos[d_labinfos['itemid'] == i]['ref_range_lower_count'])\n",
    "\n",
    "\n",
    "# print(\"Checking ref_range_upper_count\")\n",
    "# for i in target_lab_itemid:\n",
    "#     if (d_labinfos[d_labinfos['itemid'] == i]['ref_range_upper_count'] > 1).any():\n",
    "#         print(i, d_labinfos[d_labinfos['itemid'] == i]['ref_range_upper_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data info\n",
    "\n",
    "Currently the unit is taken from the original tables. A better solution is to include them in the concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR, custom_icustays_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting height data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for height : 35170\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'height']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added height entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ['subject_id', 'stay_id', 'charttime', 'height']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext('derived', 'height')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    # This line is the strange hack for notebook.tqdm\n",
    "    # print(' ', end='', flush=True)\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, df_row['stay_id'])\n",
    "        dt.append(\n",
    "            uid=100001,\n",
    "            value=df_row['height'],\n",
    "            unit='cm',\n",
    "            category='General',\n",
    "            starttime=df_row['charttime'],\n",
    "        )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added height entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting weight_durations data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for weight_durations : 287155\n",
      "Column names : ['stay_id', 'starttime', 'endtime', 'weight', 'weight_type']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:38<00:00, 24.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added weight entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ['stay_id', 'starttime', 'endtime', 'weight', 'weight_type']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'weight_durations')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, df_row['stay_id'])\n",
    "        dt.append(\n",
    "            uid=100002,\n",
    "            value=df_row['weight'],\n",
    "            unit='kg',\n",
    "            category='General, ' + df_row['weight_type'],\n",
    "            starttime=df_row['starttime'],\n",
    "            endtime=df_row['endtime'],\n",
    "        )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added weight entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting chemistry data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:53,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for chemistry : 3956323\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'albumin', 'globulin', 'total_protein', 'aniongap', 'bicarbonate', 'bun', 'calcium', 'chloride', 'creatinine', 'glucose', 'sodium', 'potassium', 'albumin_unit', 'globulin_unit', 'total_protein_unit', 'aniongap_unit', 'bicarbonate_unit', 'bun_unit', 'calcium_unit', 'chloride_unit', 'creatinine_unit', 'glucose_unit', 'sodium_unit', 'potassium_unit', 'albumin_lower', 'globulin_lower', 'total_protein_lower', 'aniongap_lower', 'bicarbonate_lower', 'bun_lower', 'calcium_lower', 'chloride_lower', 'creatinine_lower', 'glucose_lower', 'sodium_lower', 'potassium_lower', 'albumin_upper', 'globulin_upper', 'total_protein_upper', 'aniongap_upper', 'bicarbonate_upper', 'bun_upper', 'calcium_upper', 'chloride_upper', 'creatinine_upper', 'glucose_upper', 'sodium_upper', 'potassium_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:06<00:00,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chemistry (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    550862: 'albumin',\n",
    "    550930: 'globulin',\n",
    "    550976: 'total_protein',\n",
    "    550868: 'aniongap',\n",
    "    550882: 'bicarbonate',\n",
    "    551006: 'bun',\n",
    "    550893: 'calcium',\n",
    "    550902: 'chloride',\n",
    "    550912: 'creatinine',\n",
    "    550931: 'glucose',\n",
    "    550983: 'sodium',\n",
    "    550971: 'potassium',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'albumin', 'globulin', 'total_protein', 'aniongap', 'bicarbonate', 'bun', 'calcium', 'chloride', 'creatinine', 'glucose', 'sodium', 'potassium']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'chemistry')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_list:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added chemistry (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting bg data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:10,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for bg : 561212\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen', 'specimen_unit', 'specimen_lower', 'specimen_upper', 'specimen_pred', 'specimen_prob', 'so2', 'so2_unit', 'so2_lower', 'so2_upper', 'po2', 'po2_unit', 'po2_lower', 'po2_upper', 'pco2', 'pco2_unit', 'pco2_lower', 'pco2_upper', 'fio2_chartevents', 'fio2', 'fio2_unit', 'fio2_lower', 'fio2_upper', 'aado2', 'aado2_unit', 'aado2_lower', 'aado2_upper', 'aado2_calc', 'pao2fio2ratio', 'ph', 'ph_unit', 'ph_lower', 'ph_upper', 'baseexcess', 'baseexcess_unit', 'baseexcess_lower', 'baseexcess_upper', 'bicarbonate', 'bicarbonate_unit', 'bicarbonate_lower', 'bicarbonate_upper', 'totalco2', 'totalco2_unit', 'totalco2_lower', 'totalco2_upper', 'hematocrit', 'hematocrit_unit', 'hematocrit_lower', 'hematocrit_upper', 'hemoglobin', 'hemoglobin_unit', 'hemoglobin_lower', 'hemoglobin_upper', 'carboxyhemoglobin', 'carboxyhemoglobin_unit', 'carboxyhemoglobin_lower', 'carboxyhemoglobin_upper', 'methemoglobin', 'methemoglobin_unit', 'methemoglobin_lower', 'methemoglobin_upper', 'chloride', 'chloride_unit', 'chloride_lower', 'chloride_upper', 'calcium', 'calcium_unit', 'calcium_lower', 'calcium_upper', 'temperature', 'temperature_unit', 'temperature_lower', 'temperature_upper', 'potassium', 'potassium_unit', 'potassium_lower', 'potassium_upper', 'sodium', 'sodium_unit', 'sodium_lower', 'sodium_upper', 'lactate', 'lactate_unit', 'lactate_lower', 'lactate_upper', 'glucose', 'glucose_unit', 'glucose_lower', 'glucose_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:12<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added bg (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    552028: 'specimen',\n",
    "    550801: 'aado2',\n",
    "    550802: 'baseexcess',\n",
    "    550803: 'bicarbonate',\n",
    "    550804: 'totalco2',\n",
    "    550805: 'carboxyhemoglobin',\n",
    "    550806: 'chloride',\n",
    "    550808: 'calcium',\n",
    "    550809: 'glucose',\n",
    "    550810: 'hematocrit',\n",
    "    550811: 'hemoglobin',\n",
    "    550813: 'lactate',\n",
    "    550814: 'methemoglobin',\n",
    "    550816: 'fio2',\n",
    "    550817: 'so2',\n",
    "    550818: 'pco2',\n",
    "    550820: 'ph',\n",
    "    550821: 'po2',\n",
    "    550822: 'potassium',\n",
    "    550824: 'sodium',\n",
    "    550825: 'temperature',\n",
    "    223835: 'fio2_chartevents',\n",
    "    100038: 'pao2fio2ratio',  # nounit\n",
    "    100039: 'aado2_calc',\n",
    "    100040: 'specimen_pred',  # nounit\n",
    "    100041: 'specimen_prob',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen', 'specimen_pred', 'specimen_prob', 'so2', 'po2', 'pco2', 'fio2_chartevents', 'fio2', 'aado2', 'aado2_calc', 'pao2fio2ratio', 'ph', 'baseexcess', 'bicarbonate', 'totalco2', 'hematocrit', 'hemoglobin', 'carboxyhemoglobin', 'methemoglobin', 'chloride', 'calcium', 'temperature', 'potassium', 'sodium', 'lactate', 'glucose']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext('derived', 'bg')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "\n",
    "                        if id_mapping[col]//100000 == 1:\n",
    "                            unit = unit_mapping[col]\n",
    "                            lower_range = low_mapping[col]\n",
    "                            upper_range = high_mapping[col]\n",
    "\n",
    "                            if id_mapping[col] == 100039:\n",
    "                                unit = df_row['aado2_unit'],\n",
    "                                lower_range = df_row['aado2_lower'],\n",
    "                                upper_range = df_row['aado2_upper'],\n",
    "\n",
    "                        else:\n",
    "                            unit = df_row[col+'_unit'],\n",
    "                            lower_range = df_row[col+'_lower'],\n",
    "                            upper_range = df_row[col+'_upper'],\n",
    "\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=unit,\n",
    "                            lower_range=lower_range,\n",
    "                            upper_range=upper_range,\n",
    "                            category=cat_mapping[col],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added bg (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting blood_differential data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:39,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for blood_differential : 3283493\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'wbc', 'wbc_unit', 'wbc_lower', 'wbc_upper', 'basophils_abs', 'basophils_abs_unit', 'basophils_abs_lower', 'basophils_abs_upper', 'eosinophils_abs', 'eosinophils_abs_unit', 'eosinophils_abs_lower', 'eosinophils_abs_upper', 'lymphocytes_abs', 'lymphocytes_abs_unit', 'lymphocytes_abs_lower', 'lymphocytes_abs_upper', 'monocytes_abs', 'monocytes_abs_unit', 'monocytes_abs_lower', 'monocytes_abs_upper', 'neutrophils_abs', 'neutrophils_abs_unit', 'neutrophils_abs_lower', 'neutrophils_abs_upper', 'basophils', 'basophils_unit', 'basophils_lower', 'basophils_upper', 'eosinophils', 'eosinophils_unit', 'eosinophils_lower', 'eosinophils_upper', 'lymphocytes', 'lymphocytes_unit', 'lymphocytes_lower', 'lymphocytes_upper', 'monocytes', 'monocytes_unit', 'monocytes_lower', 'monocytes_upper', 'neutrophils', 'neutrophils_unit', 'neutrophils_lower', 'neutrophils_upper', 'atypical_lymphocytes', 'atypical_lymphocytes_unit', 'atypical_lymphocytes_lower', 'atypical_lymphocytes_upper', 'bands', 'bands_unit', 'bands_lower', 'bands_upper', 'immature_granulocytes', 'immature_granulocytes_unit', 'immature_granulocytes_lower', 'immature_granulocytes_upper', 'metamyelocytes', 'metamyelocytes_unit', 'metamyelocytes_lower', 'metamyelocytes_upper', 'nrbc', 'nrbc_unit', 'nrbc_lower', 'nrbc_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:07<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added blood_differential (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# impute absolute count if percentage & WBC is available\n",
    "id_mapping = {\n",
    "    551146: 'basophils',\n",
    "    552069: 'basophils_abs',\n",
    "    551200: 'eosinophils',\n",
    "    551254: 'monocytes',\n",
    "    551256: 'neutrophils',\n",
    "    552075: 'neutrophils_abs',\n",
    "    551143: 'atypical_lymphocytes',\n",
    "    551144: 'bands',\n",
    "    552135: 'immature_granulocytes',\n",
    "    551251: 'metamyelocytes',\n",
    "    551257: 'nrbc',\n",
    "\n",
    "    100003: 'wbc',  # TODO: May need to split due to category.\n",
    "    100004: 'lymphocytes',\n",
    "    100005: 'eosinophils_abs',\n",
    "    100006: 'lymphocytes_abs',\n",
    "    100007: 'monocytes_abs',\n",
    "\n",
    "    # 51300: 'wbc',\n",
    "    # 51301: 'wbc',\n",
    "    # 51755: 'wbc',\n",
    "    # [51244, 51245]: lymphocytes\n",
    "    # [52073, 51199]: eosinophils_abs\n",
    "    # [51133, 52769]: lymphocytes_abs\n",
    "    # [52074, 51253]: monocytes_abs\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'wbc', 'basophils_abs', 'eosinophils_abs', 'lymphocytes_abs', 'monocytes_abs', 'neutrophils_abs', 'basophils', 'eosinophils', 'lymphocytes', 'monocytes', 'neutrophils', 'atypical_lymphocytes', 'bands', 'immature_granulocytes', 'metamyelocytes', 'nrbc']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'blood_differential')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "\n",
    "                        if id_mapping[col]//100000 == 1:\n",
    "                            unit = unit_mapping[col]\n",
    "                            lower_range = low_mapping[col]\n",
    "                            upper_range = high_mapping[col]\n",
    "\n",
    "                            if id_mapping[col] == 100003:\n",
    "                                lower_range = df_row['wbc_lower'],\n",
    "                                upper_range = df_row['wbc_upper'],\n",
    "                            elif id_mapping[col] == 100004:\n",
    "                                lower_range = df_row['lymphocytes_lower'],\n",
    "                                upper_range = df_row['lymphocytes_upper'],\n",
    "                            elif id_mapping[col] == 100005:\n",
    "                                lower_range = df_row['eosinophils_abs_lower'],\n",
    "                                upper_range = df_row['eosinophils_abs_upper'],\n",
    "                            elif id_mapping[col] == 100006:\n",
    "                                lower_range = df_row['lymphocytes_abs_lower'],\n",
    "                                upper_range = df_row['lymphocytes_abs_upper'],\n",
    "                            elif id_mapping[col] == 100007:\n",
    "                                lower_range = df_row['monocytes_abs_lower'],\n",
    "                                upper_range = df_row['monocytes_abs_upper'],\n",
    "\n",
    "                        else:\n",
    "                            unit = df_row[col+'_unit'],\n",
    "                            lower_range = df_row[col+'_lower'],\n",
    "                            upper_range = df_row[col+'_upper'],\n",
    "\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=unit,\n",
    "                            lower_range=lower_range,\n",
    "                            upper_range=upper_range,\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added blood_differential (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiac Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting cardiac_marker data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:01,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for cardiac_marker : 430049\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'troponin_i', 'troponin_t', 'ck_mb', 'troponin_i_unit', 'troponin_t_unit', 'ck_mb_unit', 'troponin_i_lower', 'troponin_t_lower', 'ck_mb_lower', 'troponin_i_upper', 'troponin_t_upper', 'ck_mb_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added cardiac_marker (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    551002: 'troponin_i',\n",
    "    551003: 'troponin_t',\n",
    "    550911: 'ck_mb',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'troponin_i', 'troponin_t', 'ck_mb']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'cardiac_marker')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added cardiac_marker (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coagulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting coagulation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:08,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for coagulation : 1594879\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'd_dimer', 'fibrinogen', 'thrombin', 'inr', 'pt', 'ptt', 'd_dimer_unit', 'fibrinogen_unit', 'thrombin_unit', 'inr_unit', 'pt_unit', 'ptt_unit', 'd_dimer_lower', 'fibrinogen_lower', 'thrombin_lower', 'inr_lower', 'pt_lower', 'ptt_lower', 'd_dimer_upper', 'fibrinogen_upper', 'thrombin_upper', 'inr_upper', 'pt_upper', 'ptt_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added coagulation (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    551196: 'd_dimer',\n",
    "    551214: 'fibrinogen',\n",
    "    551297: 'thrombin',\n",
    "    551237: 'inr',\n",
    "    551274: 'pt',\n",
    "    551275: 'ptt',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'd_dimer', 'fibrinogen', 'thrombin', 'inr', 'pt', 'ptt']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'coagulation')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added coagulation (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete blood count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting complete_blood_count data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:47,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for complete_blood_count : 3492512\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'hematocrit', 'hemoglobin', 'mch', 'mchc', 'mcv', 'platelet', 'rbc', 'rdw', 'rdwsd', 'wbc', 'hematocrit_unit', 'hemoglobin_unit', 'mch_unit', 'mchc_unit', 'mcv_unit', 'platelet_unit', 'rbc_unit', 'rdw_unit', 'rdwsd_unit', 'wbc_unit', 'hematocrit_lower', 'hemoglobin_lower', 'mch_lower', 'mchc_lower', 'mcv_lower', 'platelet_lower', 'rbc_lower', 'rdw_lower', 'rdwsd_lower', 'wbc_lower', 'hematocrit_upper', 'hemoglobin_upper', 'mch_upper', 'mchc_upper', 'mcv_upper', 'platelet_upper', 'rbc_upper', 'rdw_upper', 'rdwsd_upper', 'wbc_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:20<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added complete_blood_count (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    551221: 'hematocrit',\n",
    "    551222: 'hemoglobin',\n",
    "    551248: 'mch',\n",
    "    551249: 'mchc',\n",
    "    551250: 'mcv',\n",
    "    551265: 'platelet',\n",
    "    551279: 'rbc',\n",
    "    551277: 'rdw',\n",
    "    552159: 'rdwsd',\n",
    "    # 551301: 'wbc', # present in blood_differential\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'hematocrit', 'hemoglobin', 'mch', 'mchc', 'mcv', 'platelet', 'rbc', 'rdw', 'rdwsd', 'wbc']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'complete_blood_count')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added complete_blood_count (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enzyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting enzyme data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:16,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for enzyme : 1787236\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'alt', 'alp', 'ast', 'amylase', 'bilirubin_total', 'bilirubin_direct', 'bilirubin_indirect', 'ck_cpk', 'ck_mb', 'ggt', 'ld_ldh', 'alt_unit', 'alp_unit', 'ast_unit', 'amylase_unit', 'bilirubin_total_unit', 'bilirubin_direct_unit', 'bilirubin_indirect_unit', 'ck_cpk_unit', 'ck_mb_unit', 'ggt_unit', 'ld_ldh_unit', 'alt_lower', 'alp_lower', 'ast_lower', 'amylase_lower', 'bilirubin_total_lower', 'bilirubin_direct_lower', 'bilirubin_indirect_lower', 'ck_cpk_lower', 'ck_mb_lower', 'ggt_lower', 'ld_ldh_lower', 'alt_upper', 'alp_upper', 'ast_upper', 'amylase_upper', 'bilirubin_total_upper', 'bilirubin_direct_upper', 'bilirubin_indirect_upper', 'ck_cpk_upper', 'ck_mb_upper', 'ggt_upper', 'ld_ldh_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:40<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added enzyme (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    550861: 'alt',\n",
    "    550863: 'alp',\n",
    "    550878: 'ast',\n",
    "    550867: 'amylase',\n",
    "    550885: 'bilirubin_total',\n",
    "    550884: 'bilirubin_indirect',\n",
    "    550883: 'bilirubin_direct',\n",
    "    550910: 'ck_cpk',\n",
    "    550911: 'ck_mb',\n",
    "    550927: 'ggt',\n",
    "    550954: 'ld_ldh',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'alt', 'alp', 'ast', 'amylase', 'bilirubin_total', 'bilirubin_direct', 'bilirubin_indirect', 'ck_cpk', 'ck_mb', 'ggt', 'ld_ldh']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'enzyme')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added enzyme (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inflamation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting inflammation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for inflammation : 118290\n",
      "Column names : ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'crp', 'crp_unit', 'crp_lower', 'crp_upper']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added inflammation (lab) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    550889: 'crp',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'crp']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'inflammation')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added inflammation (lab) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O2 delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting oxygen_delivery data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:01,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for oxygen_delivery : 829534\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'o2_flow', 'o2_flow_additional', 'o2_delivery_device_1', 'o2_delivery_device_2', 'o2_delivery_device_3', 'o2_delivery_device_4']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [04:28<00:00, 24.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added oxygen_delivery (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    227287: 'o2_flow_additional',\n",
    "\n",
    "    100012: 'o2_flow',\n",
    "    100008: 'o2_delivery_device_1',\n",
    "    100009: 'o2_delivery_device_2',\n",
    "    100010: 'o2_delivery_device_3',\n",
    "    100011: 'o2_delivery_device_4',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'stay_id', 'charttime', 'o2_flow', 'o2_flow_additional', 'o2_delivery_device_1', 'o2_delivery_device_2', 'o2_delivery_device_3', 'o2_delivery_device_4']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'oxygen_delivery')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, df_row['stay_id'])\n",
    "        for col in df.columns.tolist():\n",
    "            if col in id_mapping:\n",
    "                dt.append(\n",
    "                    uid=id_mapping[col],\n",
    "                    value=df_row[col],\n",
    "                    unit=unit_mapping[col],\n",
    "                    lower_range=low_mapping[col],\n",
    "                    upper_range=high_mapping[col],\n",
    "                    category=cat_mapping[col],\n",
    "                    starttime=df_row['charttime'],\n",
    "                )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added oxygen_delivery (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting rhythm data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:07,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for rhythm : 6184785\n",
      "Column names : ['subject_id', 'charttime', 'heart_rhythm', 'ectopy_type', 'ectopy_frequency', 'ectopy_type_secondary', 'ectopy_frequency_secondary']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [01:42<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added rhythm (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_mapping = {\n",
    "    220048: 'heart_rhythm',\n",
    "    224650: 'ectopy_type',\n",
    "    224651: 'ectopy_frequency',\n",
    "    226479: 'ectopy_type_secondary',\n",
    "    226480: 'ectopy_frequency_secondary',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'charttime', 'heart_rhythm', 'ectopy_type', 'ectopy_frequency', 'ectopy_type_secondary', 'ectopy_frequency_secondary']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext('derived', 'rhythm')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "\n",
    "        for hadm_id, stay_ids in custom_icustays_dict[df_row['subject_id']]:\n",
    "\n",
    "            for stay_id in stay_ids:\n",
    "                it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "                dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "\n",
    "                icu_intime = it.data[13]\n",
    "                icu_outtime = it.data[14]\n",
    "\n",
    "                if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                    for col in df.columns.tolist():\n",
    "                        if col in id_mapping:\n",
    "                            dt.append(\n",
    "                                uid=id_mapping[col],\n",
    "                                value=df_row[col],\n",
    "                                unit=unit_mapping[col],\n",
    "                                lower_range=low_mapping[col],\n",
    "                                upper_range=high_mapping[col],\n",
    "                                category=cat_mapping[col],\n",
    "                                starttime=df_row['charttime'],\n",
    "                            )\n",
    "                    save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "                                  stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added rhythm (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urine Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting urine_output data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:04, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for urine_output : 3497267\n",
      "Column names : ['stay_id', 'charttime', 'urineoutput']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [12:57<00:00, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added urine_output (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR+'_uo', custom_icustays_list)\n",
    "\n",
    "# ['stay_id', 'charttime', 'urineoutput']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'urine_output')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR+'_uo', df_row['stay_id'])\n",
    "        dt.append(\n",
    "            uid=100013,\n",
    "            value=df_row['urineoutput'],\n",
    "            unit='mL',\n",
    "            category='Output',\n",
    "            starttime=df_row['charttime'],\n",
    "        )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR+'_uo',\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added urine_output (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urine Output Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting urine_output_rate data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:25,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for urine_output_rate : 3497266\n",
      "Column names : ['stay_id', 'charttime', 'weight', 'uo', 'urineoutput_6hr', 'urineoutput_12hr', 'urineoutput_24hr', 'uo_mlkghr_6hr', 'uo_mlkghr_12hr', 'uo_mlkghr_24hr', 'uo_tm_6hr', 'uo_tm_12hr', 'uo_tm_24hr']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 18/44 [15:24<22:15, 51.36s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('something wrong loading file :', 34269559)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_10978/1210866799.py\", line 37, in func\n    dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR+'_uor', df_row['stay_id'])\n  File \"/workspaces/mimic-code/mimic-iv/projects/utils/data_table.py\", line 42, in load_data_dsv\n    data = load_dsv(save_path).to_dict('list')\n  File \"/workspaces/mimic-code/mimic-iv/projects/utils/data_table.py\", line 19, in load_dsv\n    return pd.read_csv(path, sep='$')\n  File \"/usr/local/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/usr/local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 69, in __init__\n    self._reader = parsers.TextReader(self.handles.handle, **kwds)\n  File \"pandas/_libs/parsers.pyx\", line 549, in pandas._libs.parsers.TextReader.__cinit__\npandas.errors.EmptyDataError: No columns to parse from file\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/tmp/ipykernel_10978/1210866799.py\", line 39, in func\n    raise ValueError(\"something wrong loading file :\",\nValueError: ('something wrong loading file :', 34269559)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10978/1210866799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mparallel_processing_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_icustays_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Added urine_output_rate (derived) entries.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10978/3309387202.py\u001b[0m in \u001b[0;36mparallel_processing_ext\u001b[0;34m(_func, _df_iter, _num_entries, _custom_icustays_list)\u001b[0m\n\u001b[1;32m     61\u001b[0m             by=[i for i in sort_list if i in df.columns.tolist()])\n\u001b[1;32m     62\u001b[0m         \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMP_NUM_PROCESSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mparallel_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMP_NUM_PROCESSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspaces/mimic-code/mimic-iv/projects/utils/multiprocessing.py\u001b[0m in \u001b[0;36mparallel_processing\u001b[0;34m(func, num_of_processes, *args)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margument_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/mimic-code/mimic-iv/projects/utils/multiprocessing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margument_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('something wrong loading file :', 34269559)"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR+'_uor', custom_icustays_list)\n",
    "\n",
    "# -- attempt to calculate urine output per hour\n",
    "# -- rate/hour is the interpretable measure of kidney function\n",
    "# -- though it is difficult to estimate from aperiodic point measures\n",
    "# -- first we get the earliest heart rate documented for the stay\n",
    "id_mapping = {\n",
    "    # 100013: 'uo', present in previous table.\n",
    "    100014: 'urineoutput_6hr',  # output within 6hr (floor)\n",
    "    100015: 'urineoutput_12hr',\n",
    "    100016: 'urineoutput_24hr',\n",
    "    100017: 'uo_mlkghr_6hr',  # (urineoutput_6hr/weight/uo_tm_6hr)\n",
    "    100018: 'uo_mlkghr_12hr',\n",
    "    100019: 'uo_mlkghr_24hr',\n",
    "    100020: 'uo_tm_6hr',  # time from last uo measurement within 6hr (floor)\n",
    "    100021: 'uo_tm_12hr',\n",
    "    100022: 'uo_tm_24hr',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['stay_id', 'charttime', 'weight', 'uo', 'urineoutput_6hr', 'urineoutput_12hr', 'urineoutput_24hr', 'uo_mlkghr_6hr', 'uo_mlkghr_12hr', 'uo_mlkghr_24hr', 'uo_tm_6hr', 'uo_tm_12hr', 'uo_tm_24hr']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'urine_output_rate')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR +\n",
    "                                '_uor', df_row['stay_id'])\n",
    "        for col in df.columns.tolist():\n",
    "            if col in id_mapping:\n",
    "                dt.append(\n",
    "                    uid=id_mapping[col],\n",
    "                    value=df_row[col],\n",
    "                    unit=unit_mapping[col],\n",
    "                    lower_range=low_mapping[col],\n",
    "                    upper_range=high_mapping[col],\n",
    "                    category=cat_mapping[col],\n",
    "                    starttime=df_row['charttime'],\n",
    "                )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR+'_uor',\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added urine_output_rate (derived) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vent settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting ventilator_setting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:03,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for ventilator_setting : 1067028\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'respiratory_rate_set', 'respiratory_rate_total', 'respiratory_rate_spontaneous', 'minute_volume', 'tidal_volume_set', 'tidal_volume_observed', 'tidal_volume_spontaneous', 'plateau_pressure', 'peep', 'fio2', 'ventilator_mode', 'ventilator_mode_hamilton', 'ventilator_type']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [09:30<00:00, 40.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added ventilator_setting (chart) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR+'_vent', custom_icustays_list)\n",
    "\n",
    "id_mapping = {\n",
    "    224688: 'respiratory_rate_set',\n",
    "    224690: 'respiratory_rate_total',\n",
    "    224689: 'respiratory_rate_spontaneous',\n",
    "    224687: 'minute_volume',\n",
    "    224684: 'tidal_volume_set',\n",
    "    224685: 'tidal_volume_observed',\n",
    "    224686: 'tidal_volume_spontaneous',\n",
    "    224696: 'plateau_pressure',\n",
    "    100023: 'peep',\n",
    "    # 223835: 'fio2',  # same as fio2_chartevents\n",
    "    223849: 'ventilator_mode',\n",
    "    229314: 'ventilator_mode_hamilton',\n",
    "    223848: 'ventilator_type',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'stay_id', 'charttime', 'respiratory_rate_set', 'respiratory_rate_total', 'respiratory_rate_spontaneous', 'minute_volume', 'tidal_volume_set', 'tidal_volume_observed', 'tidal_volume_spontaneous', 'plateau_pressure', 'peep', 'fio2', 'ventilator_mode', 'ventilator_mode_hamilton', 'ventilator_type']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'ventilator_setting')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR+'_vent', df_row['stay_id'])\n",
    "        for col in df.columns.tolist():\n",
    "            if col in id_mapping:\n",
    "                dt.append(\n",
    "                    uid=id_mapping[col],\n",
    "                    value=df_row[col],\n",
    "                    unit=unit_mapping[col],\n",
    "                    lower_range=low_mapping[col],\n",
    "                    upper_range=high_mapping[col],\n",
    "                    category=cat_mapping[col],\n",
    "                    starttime=df_row['charttime'],\n",
    "                )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR+'_vent',\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added ventilator_setting (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vital Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting vitalsign data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:33,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for vitalsign : 10249430\n",
      "Column names : ['subject_id', 'stay_id', 'charttime', 'heart_rate', 'sbp', 'dbp', 'mbp', 'sbp_ni', 'dbp_ni', 'mbp_ni', 'resp_rate', 'temperature', 'temperature_site', 'spo2', 'glucose']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR+'_vs', custom_icustays_list)\n",
    "\n",
    "id_mapping = {\n",
    "    220045: 'heart_rate',\n",
    "    100024: 'sbp',\n",
    "    100025: 'dbp',\n",
    "    100026: 'mbp',\n",
    "    220179: 'sbp_ni',\n",
    "    220180: 'dbp_ni',\n",
    "    220181: 'mbp_ni',\n",
    "    100027: 'resp_rate',\n",
    "    100028: 'temperature',\n",
    "    224642: 'temperature_site',\n",
    "    220277: 'spo2',\n",
    "    100029: 'glucose_chartevents',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'stay_id', 'charttime', 'heart_rate', 'sbp', 'dbp', 'mbp', 'sbp_ni', 'dbp_ni', 'mbp_ni', 'resp_rate', 'temperature', 'temperature_site', 'spo2', 'glucose']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'vitalsign', _chunk=100000)\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR+'_vs', df_row['stay_id'])\n",
    "        for col in df.columns.tolist():\n",
    "            if col in id_mapping:\n",
    "                dt.append(\n",
    "                    uid=id_mapping[col],\n",
    "                    value=df_row[col],\n",
    "                    unit=unit_mapping[col],\n",
    "                    lower_range=low_mapping[col],\n",
    "                    upper_range=high_mapping[col],\n",
    "                    category=cat_mapping[col],\n",
    "                    starttime=df_row['charttime'],\n",
    "                )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR+'_vs',\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added vitalsign (chart) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antibiotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (query_schema_core,\n",
    "#  query_schema_hosp,\n",
    "#  query_schema_icu,\n",
    "#  query_schema_derived,\n",
    "#  conn) = connect_db()\n",
    "\n",
    "# # ['subject_id', 'hadm_id', 'stay_id', 'antibiotic', 'route', 'starttime', 'stoptime']\n",
    "# df = get_database_table_as_dataframe(conn, query_schema_derived, 'antibiotic')\n",
    "# df = df[df.stay_id.isin(custom_icustays_list)]\n",
    "\n",
    "\n",
    "# def func(dfs, pid):\n",
    "\n",
    "# \n",
    "# \n",
    "\n",
    "#     df = dfs[0]\n",
    "#     it = InfoTable()\n",
    "#     dt = DataTable()\n",
    "#     for df_i in df.iterrows():\n",
    "#         df_row = df_i[1]\n",
    "#         dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR, df_row['stay_id'])\n",
    "#         dt.append(\n",
    "#             uid=100030,\n",
    "#             value=df_row['antibiotic'],\n",
    "#             category=df_row['route'],\n",
    "#             starttime=df_row['starttime'],\n",
    "#             endtime=df_row['stoptime'],\n",
    "#         )\n",
    "#         save_data_dsv(STRUCTURED_EXPORT_DIR,\n",
    "#                       df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "# dfs = split_df(df, MP_NUM_PROCESSES)\n",
    "# parallel_processing(func, MP_NUM_PROCESSES, dfs)\n",
    "\n",
    "# print(\"Added antibiotic (hosp.prescriptions) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting inputevents data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for inputevents : 782373\n",
      "Column names : ['subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'storetime', 'itemid', 'amount', 'amountuom', 'rate', 'rateuom', 'orderid', 'linkorderid', 'ordercategoryname', 'secondaryordercategoryname', 'ordercomponenttypedescription', 'ordercategorydescription', 'patientweight', 'totalamount', 'totalamountuom', 'isopenbag', 'continueinnextdept', 'cancelreason', 'statusdescription', 'originalamount', 'originalrate']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:56<00:00, 35.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added (medication) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR+'_med', custom_icustays_list)\n",
    "\n",
    "med_ids = [\n",
    "    220995,  # Sodium Bicarbonate 8.4%\n",
    "    221794,  # Furosemide (Lasix) **\n",
    "    228340,  # Furosemide (Lasix) 250/50 **\n",
    "    # 100037,  # Furosemide (Lasix)\n",
    "    221986,  # Milrinone\n",
    "    229068,  # Protamine sulfate\n",
    "    229639,  # Bumetanide (Bumex)\n",
    "\n",
    "    221653,  # Dobutamine\n",
    "    221662,  # Dopamine\n",
    "    221289,  # Epinephrine\n",
    "    229617,  # Epinephrine. ~145 entries only\n",
    "    # 100036,  # Epinephrine\n",
    "    221906,  # Norepinephrine\n",
    "    221749,  # Phenylephrine\n",
    "    222315,  # Vasopressin\n",
    "]\n",
    "id_mapping = {\n",
    "    221794: 100037,\n",
    "    228340: 100037,\n",
    "    221289: 100036,\n",
    "    229617: 100036,\n",
    "}\n",
    "\n",
    "(query_schema_core,\n",
    " query_schema_hosp,\n",
    " query_schema_icu,\n",
    " query_schema_derived,\n",
    " conn) = connect_db()\n",
    "\n",
    "df_iter, num_entries = get_database_table_as_dataframe(\n",
    "    conn, query_schema_icu, 'inputevents',\n",
    "    _filter_col='itemid',\n",
    "    _filter_col_val=tuple(med_ids),\n",
    "    _chunk_size=10000*MP_NUM_PROCESSES)\n",
    "num_entries = math.ceil(num_entries / (10000*MP_NUM_PROCESSES))\n",
    "# df = df[df.stay_id.isin(custom_icustays_list)]\n",
    "# df = df.sort_values('stay_id')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR +\n",
    "                                '_med', df_row['stay_id'])\n",
    "        uid = df_row['itemid']\n",
    "        dt.append(\n",
    "            uid=id_mapping[uid] if uid in id_mapping else uid,\n",
    "            value=df_row['amount'],\n",
    "            unit=df_row['amountuom'],\n",
    "            rate=df_row['rate'],\n",
    "            rate_unit=df_row['rateuom'],\n",
    "            category='Medication',\n",
    "            starttime=df_row['starttime'],\n",
    "            endtime=df_row['endtime'],\n",
    "        )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR+'_med',\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "for df in tqdm(df_iter, total=num_entries):\n",
    "    df = df[df.stay_id.isin(custom_icustays_list)]\n",
    "    df = df.sort_values(by=['subject_id', 'hadm_id',\n",
    "                        'stay_id', 'starttime', 'endtime'])\n",
    "    dfs = split_df(df, MP_NUM_PROCESSES)\n",
    "    parallel_processing(func, MP_NUM_PROCESSES, dfs)\n",
    "\n",
    "print(\"Added (medication) entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDIGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy .dsv files.\n",
      "Database: mimiciv\n",
      "Username: mimiciv\n",
      ">>>>> Connected to DB <<<<<\n",
      "Getting kdigo_stages data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:17,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for kdigo_stages : 4111003\n",
      "Column names : ['subject_id', 'hadm_id', 'stay_id', 'charttime', 'creat_low_past_7day', 'creat_low_past_48hr', 'creat', 'aki_stage_creat', 'uo_rt_6hr', 'uo_rt_12hr', 'uo_rt_24hr', 'aki_stage_uo', 'aki_stage']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [26:03<00:00, 30.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added kdigo_stages (derived) entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR+'_kdigo', custom_icustays_list)\n",
    "\n",
    "id_mapping = {\n",
    "    100031: 'creat_low_past_48hr',\n",
    "    100032: 'creat_low_past_7day',\n",
    "    100033: 'aki_stage_creat',\n",
    "    100034: 'aki_stage_uo',\n",
    "    100035: 'aki_stage',\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'stay_id', 'charttime', 'creat_low_past_7day', 'creat_low_past_48hr', 'creat', 'aki_stage_creat', 'uo_rt_6hr', 'uo_rt_12hr', 'uo_rt_24hr', 'aki_stage_uo', 'aki_stage']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'kdigo_stages')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "        dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR+'_kdigo', df_row['stay_id'])\n",
    "        for col in df.columns.tolist()[4:]:\n",
    "            if col in id_mapping:\n",
    "                dt.append(\n",
    "                    uid=id_mapping[col],\n",
    "                    value=df_row[col],\n",
    "                    unit=unit_mapping[col],\n",
    "                    lower_range=low_mapping[col],\n",
    "                    upper_range=high_mapping[col],\n",
    "                    category=cat_mapping[col],\n",
    "                    starttime=df_row['charttime'],\n",
    "                )\n",
    "        save_data_dsv(STRUCTURED_EXPORT_DIR+'_kdigo',\n",
    "                      df_row['stay_id'], pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added kdigo_stages (derived) entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(files):\n",
    "    for f in files:\n",
    "        main_path = os.path.join(STRUCTURED_EXPORT_DIR, f)\n",
    "        df = pd.read_csv(main_path, sep='$')\n",
    "\n",
    "        path = os.path.join(STRUCTURED_EXPORT_DIR+'_kdigo', f)\n",
    "        df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        path = os.path.join(STRUCTURED_EXPORT_DIR+'_med', f)\n",
    "        df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        path = os.path.join(STRUCTURED_EXPORT_DIR+'_uo', f)\n",
    "        df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        path = os.path.join(STRUCTURED_EXPORT_DIR+'_uor', f)\n",
    "        df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        path = os.path.join(STRUCTURED_EXPORT_DIR+'_vent', f)\n",
    "        df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        path = os.path.join(STRUCTURED_EXPORT_DIR+'_vs', f)\n",
    "        df = pd.concat([df, pd.read_csv(path, sep='$')])\n",
    "\n",
    "        sort_list = ['starttime', 'uid']\n",
    "        df = df.sort_values(by=sort_list)\n",
    "\n",
    "        df.to_csv(main_path, na_rep='', sep='$', index=False)\n",
    "\n",
    "\n",
    "data_files = [i for i in os.listdir(STRUCTURED_EXPORT_DIR) if 'data' in i]\n",
    "parallel_processing(func, MP_NUM_PROCESSES, data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dummy_files(STRUCTURED_EXPORT_DIR_TESTING, custom_icustays_list)\n",
    "\n",
    "id_mapping = {\n",
    "    551221: 'hematocrit',\n",
    "    551222: 'hemoglobin',\n",
    "    551248: 'mch',\n",
    "    551249: 'mchc',\n",
    "    551250: 'mcv',\n",
    "    551265: 'platelet',\n",
    "    551279: 'rbc',\n",
    "    551277: 'rdw',\n",
    "    552159: 'rdwsd',\n",
    "    # 551301: 'wbc', # present in blood_differential\n",
    "}\n",
    "(id_mapping,\n",
    " unit_mapping,\n",
    " low_mapping,\n",
    " high_mapping,\n",
    " cat_mapping) = create_mappings(id_mapping)\n",
    "\n",
    "# ['subject_id', 'hadm_id', 'charttime', 'specimen_id', 'hematocrit', 'hemoglobin', 'mch', 'mchc', 'mcv', 'platelet', 'rbc', 'rdw', 'rdwsd', 'wbc']\n",
    "df_iter, num_entries = get_database_table_as_dataframe_ext(\n",
    "    'derived', 'complete_blood_count')\n",
    "\n",
    "\n",
    "def func(dfs, pid):\n",
    "\n",
    "    df = dfs[0]\n",
    "    it = InfoTable()\n",
    "    dt = DataTable()\n",
    "    for df_i in df.iterrows():\n",
    "        df_row = df_i[1]\n",
    "\n",
    "        if df_row['subject_id'] not in custom_icustays_dict:\n",
    "            continue\n",
    "        if df_row['hadm_id'] not in custom_icustays_dict[df_row['subject_id']]:\n",
    "            continue\n",
    "\n",
    "        stay_ids = custom_icustays_dict[df_row['subject_id']\n",
    "                                        ][df_row['hadm_id']]\n",
    "\n",
    "        for stay_id in stay_ids:\n",
    "            it.data = load_info_dsv(STRUCTURED_EXPORT_DIR, stay_id)\n",
    "            dt.data = load_data_dsv(STRUCTURED_EXPORT_DIR_TESTING, stay_id)\n",
    "\n",
    "            icu_intime = it.data[13]\n",
    "            icu_outtime = it.data[14]\n",
    "\n",
    "            if icu_intime <= df_row['charttime'] <= icu_outtime:\n",
    "                for col in df.columns.tolist():\n",
    "                    if col in id_mapping:\n",
    "                        dt.append(\n",
    "                            uid=id_mapping[col],\n",
    "                            value=df_row[col],\n",
    "                            unit=df_row[col+'_unit'],\n",
    "                            lower_range=df_row[col+'_lower'],\n",
    "                            upper_range=df_row[col+'_upper'],\n",
    "                            category=cat_mapping[col],\n",
    "                            specimen_id=df_row['specimen_id'],\n",
    "                            starttime=df_row['charttime'],\n",
    "                        )\n",
    "                save_data_dsv(STRUCTURED_EXPORT_DIR_TESTING,\n",
    "                              stay_id, pd.DataFrame(dt.data))\n",
    "\n",
    "\n",
    "parallel_processing_ext(func, df_iter, num_entries, custom_icustays_list)\n",
    "print(\"Added complete_blood_count (lab) entries.\")\n",
    "\n",
    "\n",
    "data_files1 = [i for i in os.listdir(STRUCTURED_EXPORT_DIR) if 'data' in i]\n",
    "data_files2 = [i for i in os.listdir(\n",
    "    STRUCTURED_EXPORT_DIR_TESTING) if 'data' in i]\n",
    "\n",
    "\n",
    "def func(data_files1, data_files2, pid):\n",
    "\n",
    "    for f1, f2 in tqdm(zip(sorted(data_files1), sorted(data_files2)),\n",
    "                       total=len(data_files1)):\n",
    "\n",
    "        assert f1 == f2, f\"{f1} {f2}\"\n",
    "        path1 = os.path.join(STRUCTURED_EXPORT_DIR, f1)\n",
    "        path2 = os.path.join(STRUCTURED_EXPORT_DIR_TESTING, f2)\n",
    "\n",
    "        data1 = pd.read_csv(path1, sep='$').to_dict('list')\n",
    "        data1 = {k: np.array(v) if len(v) > 0 else np.array([], dtype=int)\n",
    "                 for k, v in data1.items()}\n",
    "        data2 = pd.read_csv(path2, sep='$').to_dict('list')\n",
    "        data2 = {k: np.array(v) if len(v) > 0 else np.array([], dtype=int)\n",
    "                 for k, v in data2.items()}\n",
    "\n",
    "        _data1_flag = data1['uid']\n",
    "        _data2_flag = data2['uid']\n",
    "        for k in id_mapping.values():\n",
    "            if data1['uid'][_data1_flag == k].size > 0 or \\\n",
    "                    data2['uid'][_data2_flag == k].size > 0:\n",
    "                assert data1['uid'][_data1_flag == k] == \\\n",
    "                    data2['uid'][_data2_flag == k]\n",
    "\n",
    "\n",
    "parallel_processing(func, MP_NUM_PROCESSES, data_files1, data_files2)\n",
    "\n",
    "\n",
    "def func(files, pid):\n",
    "    for f in tqdm(files):\n",
    "        os.remove(os.path.join(STRUCTURED_EXPORT_DIR_TESTING, f))\n",
    "\n",
    "\n",
    "parallel_processing(func, MP_NUM_PROCESSES, data_files2)\n",
    "os.rmdir(STRUCTURED_EXPORT_DIR_TESTING)\n",
    "\n",
    "print(\"Checked complete_blood_count (lab) entries.\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
